{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import spacy\n",
    "import langdetect\n",
    "from tqdm.notebook import tqdm\n",
    "import pdfplumber\n",
    "import fitz\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import traceback\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define headings in the document using word size function (PDFPlumber)\n",
    "def word_ratio_func(word):\n",
    "    try:\n",
    "        # calculate word size parameters\n",
    "        word_length = len(word[4])\n",
    "        word_bottom = float(word[1])\n",
    "        word_top = float(word[3])\n",
    "        return abs(word_bottom - word_top), word_length, word[4]\n",
    "        \n",
    "    except:\n",
    "        # in case of error, return zeros\n",
    "        return 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define headings in the document using word size function (Fitz)\n",
    "def word_ratio_func(word):\n",
    "    try:\n",
    "        # calculate word size parameters\n",
    "        word_length = len(word[\"text\"])\n",
    "        word_bottom = float(word['bottom'])\n",
    "        word_top = float(word['top'])\n",
    "        return (word_bottom - word_top), word_length, word[\"text\"]\n",
    "        \n",
    "    except:\n",
    "        # in case of error, return zeros\n",
    "        return 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text\n",
    "def preprocess_text(texts):\n",
    "\n",
    "    # join the text and perform cleansing operations\n",
    "    text = \"\".join(texts.values()).strip(\"●\").strip(\"*\")\n",
    "    text = text.split(\"\\n\")\n",
    "    text = [x for x in text if x != '' and x.startswith(\"Source\") == False]\n",
    "    text = [x[0].replace(\"●\", \"\") + x[1:] if x[0] == \"●\" else x for x in text]\n",
    "    text = [x[0].replace(\"1\", \"\") + x[1:] if x[1:3] in [\"Q1\", \"Q2\", \"Q3\", \"Q4\"] else x for x in text]\n",
    "    text = text[2:]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define if table is correctly identified by calculating digit to character ratio\n",
    "def digit_character_ratio(s):\n",
    "    digit_count = 0\n",
    "    char_count = 0\n",
    "\n",
    "    for char in s:\n",
    "        if char.isdigit():\n",
    "            digit_count += 1\n",
    "        if char.isalpha() or char.isdigit():\n",
    "            char_count += 1\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if char_count == 0:\n",
    "        return 0\n",
    "\n",
    "    return digit_count / char_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "# Define similarity function\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Into Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform pdf into the text\n",
    "def process_pdf(pdf_paths):\n",
    "    \n",
    "    # store the pdf text and headings in dictionaries\n",
    "    pdf_texts = {}\n",
    "    pdf_headings = {}\n",
    "\n",
    "    # iterate over the pdf files\n",
    "    for file_path in tqdm(pdf_paths):\n",
    "\n",
    "        # file_path = \"ShareholderLetters/Investor-Letter-Q1-2012.pdf\"\n",
    "        # file_path = \"ShareholderLetters/Investor-Letter-Q3-2011.pdf\"\n",
    "        # file_path = \"ShareholderLetters/July-Investor-Letter-1130am.pdf\"\n",
    "        # file_path = \"ShareholderLetters/July2014EarningsLetter_7.21.14_final.pdf\"\n",
    "        # file_path = \"ShareholderLetters/Q4_14_Letter_to_shareholders.pdf\"\n",
    "        # file_path = \"ShareholderLetters/FINAL-Q1-23-Shareholder-Letter.pdf\"\n",
    "        # file_path = \"ShareholderLetters/FINAL-Q2-23-Shareholder-Letter.pdf\"\n",
    "\n",
    "        try:\n",
    "\n",
    "            # store the text and headings within one pdf file\n",
    "            texts = {}\n",
    "            headings = []\n",
    "            headings_count = 0\n",
    "            fitz_flag = False\n",
    "\n",
    "            # open the pdf file using pdfplumber library\n",
    "            plumber_reader = pdfplumber.open(file_path)\n",
    "\n",
    "            # for page_number in range(len(fitz_reader)):\n",
    "            # iterate over pages in the pdf document\n",
    "            for page_number in range(0, len(plumber_reader.pages)):\n",
    "\n",
    "                # get the specific page from the pdf plumber\n",
    "                plumber_page = plumber_reader.pages[page_number]\n",
    "                # get text from page using pdf plumber\n",
    "                text = plumber_page.extract_text()\n",
    "\n",
    "                # if text is not correctly extracted and spaced using pdf plumber\n",
    "                if len(text.split(\" \")) / len(text) < 0.15 or fitz_flag:\n",
    "                    # set fitz library flag as true for further pages\n",
    "                    fitz_flag = True\n",
    "                    # open the pdf file using fitz library\n",
    "                    fitz_reader = fitz.open(file_path)\n",
    "                    # get the specific page from the fitz library\n",
    "                    fitz_page = fitz_reader.load_page(page_number)\n",
    "                    # get text from page using fitz library\n",
    "                    text = fitz_page.get_text()\n",
    "\n",
    "                # find table from the page\n",
    "                table = plumber_page.extract_tables()\n",
    "                # if table exists on the page\n",
    "                if len(table):\n",
    "                    # define the beginning of table\n",
    "                    start_table = table[0][0][0].split(\"\\n\")[0]\n",
    "                    # define the end of table\n",
    "                    end_table = table[-1][-1]\n",
    "                    end_table = [x for x in end_table if x is not None][-1]\n",
    "                    # if table has non-empty start and ending\n",
    "                    if start_table != '' and end_table != '':\n",
    "                        # flatten the table list of words and digits\n",
    "                        table_list = [item for sublist in table for subsublist in sublist for item in subsublist]\n",
    "                        # remove None values from the list\n",
    "                        table_list = [x for x in table_list if x is not None]\n",
    "                        # join the list as single string\n",
    "                        table_list = \" \".join(table_list)\n",
    "                        # calculate the digit to character ratio\n",
    "                        ratio = digit_character_ratio(table_list)\n",
    "                        # remove table if digit to character ratio is over 0.2, meaning that table contains numeric data\n",
    "                        if ratio > 0.2:\n",
    "                            # update the page text by removing table\n",
    "                            text = text.split(start_table)[0] + text.split(end_table)[-1]\n",
    "\n",
    "                # add text to dictionary of texts\n",
    "                texts[page_number] = text\n",
    "\n",
    "                # words = page.get_text(\"words\")\n",
    "                ### get headings from page\n",
    "                # extract words\n",
    "                words = plumber_page.extract_words()\n",
    "                word_count = 0\n",
    "                # iterate over words\n",
    "                while word_count < len(words):\n",
    "                    # find if the words are large enough to be headings by calculating their size\n",
    "                    word_size, word_length, word_text = word_ratio_func(words[word_count])\n",
    "                    heading = []\n",
    "\n",
    "                    # if word size is over 13.5, this means that the word is heading\n",
    "                    if word_size > 13.5 and word_length > 1:\n",
    "                        # append the following words if they satisfy this heading size condition\n",
    "                        while True:\n",
    "                            heading.append(word_text)\n",
    "                            word_count += 1\n",
    "                            if word_count >= len(words):\n",
    "                                break\n",
    "                            word_size, word_length, word_text = word_ratio_func(words[word_count])\n",
    "                            # if word is small again, break the loop and finish the heading\n",
    "                            if not word_size > 13.5 and word_length > 1:\n",
    "                                headings.append(\" \".join(heading))\n",
    "                                # add the indent of 10 words to avoid issues \n",
    "                                word_count += 10\n",
    "                                break\n",
    "                    headings_count += 1\n",
    "                    word_count += 1\n",
    "        \n",
    "                # break if the page covers the reference section\n",
    "                if \"Reference\" in heading or page_number == 10:\n",
    "                    break\n",
    "            \n",
    "            # preprocess the text\n",
    "            text = preprocess_text(texts)\n",
    "            final_text = \" \".join(text).strip()\n",
    "\n",
    "            \n",
    "\n",
    "            # optionally, export the text to a txt file\n",
    "            # with open(\"Txt/\" + file_path.split(\"/\")[-1].split(\".\")[0] + \".txt\", \"w\", encoding='utf-8') as f:\n",
    "            #     f.write(final_text)\n",
    "\n",
    "            # add the text to the dictionary\n",
    "            pdf_texts[file_path.split(\"/\")[-1].split(\".\")[0]] = final_text\n",
    "            # clean the headings\n",
    "            headings = [x.replace(\"\\u200b\", \"remove\") for x in headings]\n",
    "            headings = [x for x in headings if not re.search(\"remove\", x)]    \n",
    "            # add the headings to the dictionary\n",
    "            pdf_headings[file_path.split(\"/\")[-1].split(\".\")[0]] = headings\n",
    "\n",
    "            # break\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            # in case of error, print the specifics of issue\n",
    "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "            traceback_details = traceback.extract_tb(exc_traceback)\n",
    "            filename = traceback_details[-1][0]\n",
    "            line_no = traceback_details[-1][1]\n",
    "            func = traceback_details[-1][2]\n",
    "            print(f\"Exception occurred in file {filename} at line {line_no} in function {func}\")\n",
    "            print(f\"Exception type: {exc_type.__name__}, Exception message: {str(e)}\")\n",
    "\n",
    "            # break\n",
    "\n",
    "            # continue\n",
    "    \n",
    "    return pdf_texts, pdf_headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths for the pdf files\n",
    "folder_path = \"ShareholderLetters/\" # put '/' sign at the end of the folder\n",
    "file_paths = []\n",
    "for root, directories, files in os.walk(folder_path):\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(root, filename)\n",
    "        file_paths.append(filepath)\n",
    "\n",
    "# Transform pdf files into texts and headings and store them as dictionaries\n",
    "pdf_texts, pdf_headings = process_pdf(file_paths) # total run time: 2 min 20 s 20 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pdf texts and headings to pickle files\n",
    "# with open(\"pdf_texts2.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(pdf_texts, f)\n",
    "# with open(\"pdf_headings2.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(pdf_headings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table found\n",
      "0.5042918454935622\n"
     ]
    }
   ],
   "source": [
    "# file_path = \"ShareholderLetters/Investor_Letter_Q12013.pdf\"\n",
    "# file_path = \"ShareholderLetters/FINAL-Q3-22-Shareholder-Letter.pdf\"\n",
    "# file_path = \"ShareholderLetters/Investor-Letter-Q3-2011.pdf\"\n",
    "# file_path = \"ShareholderLetters/July-Investor-Letter-1130am.pdf\"\n",
    "# file_path = \"ShareholderLetters/July2014EarningsLetter_7.21.14_final.pdf\"\n",
    "# file_path = \"ShareholderLetters/Q3_14_Letter_to_shareholders.pdf\"\n",
    "# file_path = \"ShareholderLetters/Q4_14_Letter_to_shareholders.pdf\"\n",
    "# file_path = \"ShareholderLetters/FINAL-Q2-23-Shareholder-Letter.pdf\"\n",
    "# file_path = \"ShareholderLetters/FINAL-Q1-23-Shareholder-Letter.pdf\"\n",
    "file_path = \"ShareholderLetters/Investor-Letter-Q3-2011.pdf\"\n",
    "# file_path = \"ShareholderLetters/Investor-Letter-Q42012-01.pdf\"\n",
    "\n",
    "page_number = 0\n",
    "\n",
    "pdf_plumber = pdfplumber.open(file_path)\n",
    "plumber_page = pdf_plumber.pages[page_number]\n",
    "\n",
    "fitz_reader = fitz.open(file_path)\n",
    "fitz_page = fitz_reader.load_page(page_number)\n",
    "text = fitz_page.get_text()\n",
    "\n",
    "plumber_text = plumber_page.extract_text()\n",
    "table = plumber_page.extract_tables()\n",
    "\n",
    "if len(plumber_page.extract_tables()):\n",
    "    print(\"Table found\")\n",
    "    start_table = plumber_page.extract_tables()[0][0][0].split(\"\\n\")[0]\n",
    "    if not re.search(start_table, text):\n",
    "        start_table = start_table.replace(\" \", \"\")\n",
    "    end_table = plumber_page.extract_tables()[-1][-1]\n",
    "    end_table = [x for x in end_table if x is not None]\n",
    "    end_table = end_table[-1]\n",
    "    if start_table != '' and end_table != '':\n",
    "        table_list = plumber_page.extract_tables()\n",
    "        table_list = [item for sublist in table_list for subsublist in sublist for item in subsublist]\n",
    "        table_list = [x for x in table_list if x is not None]\n",
    "        table_list = \" \".join(table_list)\n",
    "        ratio = digit_character_ratio(table_list)\n",
    "        print(ratio)\n",
    "        if ratio > 0.2:\n",
    "            text_2 = text.split(start_table)[0] + text.split(end_table)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pdfreader is not good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table found\n"
     ]
    }
   ],
   "source": [
    "pdf_document = \"ShareholderLetters/Investor-Letter-Q1-2012.pdf\"\n",
    "pdf_document = \"ShareholderLetters/FINAL-Q3-22-Shareholder-Letter.pdf\"\n",
    "\n",
    "pdf_plumber = pdfplumber.open(pdf_document)\n",
    "page = pdf_plumber.pages[11]\n",
    "table = page.extract_tables()\n",
    "if len(table):\n",
    "    print(\"Table found\")\n",
    "    start_table = table[0][0][0]\n",
    "    end_table = table[0][-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Revenues $ 7,925,589 $ 7,970,141 $ 7,483,467 $ 23,763,497 $ 21,988,526',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Cost of revenues 4,788,665 4,690,755 4,206,589 13,764,125 12,093,108',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Marketing 567,954 574,960 635,948 1,698,892 1,752,433',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Technology and development 662,739 716,846 563,887 2,037,115 1,626,415',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['General and administrative 373,213 409,297 321,790 1,180,438 953,831',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Operating income 1,533,018 1,578,283 1,755,253 5,082,927 5,562,739',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Other income (expense):', None, None, None, None, None, None, None, None],\n",
       "  ['Interest expense (172,575) (175,455) (190,429) (535,609) (576,191)',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Interest and other income 261,404 220,226 96,135 677,275 302,702',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Income before income taxes 1,621,847 1,623,054 1,660,959 5,224,593 5,289,250',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Provision for income taxes (223,605) (182,103) (211,888) (787,953) (780,451)',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Net income',\n",
       "   '$ 1,398,242',\n",
       "   '',\n",
       "   '$ 1,440,951',\n",
       "   '',\n",
       "   '$ 1,449,071',\n",
       "   '',\n",
       "   '$ 4,436,640',\n",
       "   ''],\n",
       "  ['', None, None, None, None, None, None, None, None],\n",
       "  ['Earnings per share:', None, None, None, None, None, None, None, None],\n",
       "  ['Basic $ 3.14 $ 3.24 $ 3.27 $ 9.98 $ 10.18',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Diluted $ 3.10 $ 3.20 $ 3.19 $ 9.83 $ 9.90',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Weighted-average shares of common stock outstanding:',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Basic 444,878 444,557 442,778 444,529 443,052',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  ['Diluted 450,344 450,169 454,925 451,168 455,230',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None]]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Revenues $ 7,925,589 $ 7,970,141 $ 7,483,467 $ 23,763,497 $ 21,988,526</th>\n",
       "      <th colspan=\"8\" halign=\"left\">NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Cost of revenues 4,788,665 4,690,755 4,206,589 13,764,125 12,093,108</th>\n",
       "      <th colspan=\"8\" halign=\"left\">NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Marketing 567,954 574,960 635,948 1,698,892 1,752,433</th>\n",
       "      <th colspan=\"8\" halign=\"left\">NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Technology and development 662,739 716,846 563,887 2,037,115 1,626,415</th>\n",
       "      <th colspan=\"8\" halign=\"left\">NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>General and administrative 373,213 409,297 321,790 1,180,438 953,831</th>\n",
       "      <th colspan=\"8\" halign=\"left\">NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Operating income 1,533,018 1,578,283 1,755,253 5,082,927 5,562,739</th>\n",
       "      <th colspan=\"8\" halign=\"left\">NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Other income (expense):</th>\n",
       "      <th colspan=\"8\" halign=\"left\">NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Interest expense (172,575) (175,455) (190,429) (535,609) (576,191)</th>\n",
       "      <th colspan=\"8\" halign=\"left\">NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Interest and other income 261,404 220,226 96,135 677,275 302,702</th>\n",
       "      <th colspan=\"8\" halign=\"left\">NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Income before income taxes 1,621,847 1,623,054 1,660,959 5,224,593 5,289,250</th>\n",
       "      <th colspan=\"8\" halign=\"left\">NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Provision for income taxes (223,605) (182,103) (211,888) (787,953) (780,451)</th>\n",
       "      <th colspan=\"8\" halign=\"left\">NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Net income</th>\n",
       "      <th>$ 1,398,242</th>\n",
       "      <th></th>\n",
       "      <th>$ 1,440,951</th>\n",
       "      <th></th>\n",
       "      <th>$ 1,449,071</th>\n",
       "      <th></th>\n",
       "      <th>$ 4,436,640</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Earnings per share:</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Basic $ 3.14 $ 3.24 $ 3.27 $ 9.98 $ 10.18</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Diluted $ 3.10 $ 3.20 $ 3.19 $ 9.83 $ 9.90</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Weighted-average shares of common stock outstanding:</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Basic 444,878 444,557 442,778 444,529 443,052</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Diluted 450,344 450,169 454,925 451,168 455,230</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(Revenues $ 7,925,589 $ 7,970,141 $ 7,483,467 $ 23,763,497 $ 21,988,526, Cost of revenues 4,788,665 4,690,755 4,206,589 13,764,125 12,093,108, Marketing 567,954 574,960 635,948 1,698,892 1,752,433, Technology and development 662,739 716,846 563,887 2,037,115 1,626,415, General and administrative 373,213 409,297 321,790 1,180,438 953,831, Operating income 1,533,018 1,578,283 1,755,253 5,082,927 5,562,739, Other income (expense):, Interest expense (172,575) (175,455) (190,429) (535,609) (576,191), Interest and other income 261,404 220,226 96,135 677,275 302,702, Income before income taxes 1,621,847 1,623,054 1,660,959 5,224,593 5,289,250, Provision for income taxes (223,605) (182,103) (211,888) (787,953) (780,451), Net income, , Earnings per share:, Basic $ 3.14 $ 3.24 $ 3.27 $ 9.98 $ 10.18, Diluted $ 3.10 $ 3.20 $ 3.19 $ 9.83 $ 9.90, Weighted-average shares of common stock outstanding:, Basic 444,878 444,557 442,778 444,529 443,052, Diluted 450,344 450,169 454,925 451,168 455,230), (nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, $ 1,398,242, nan, nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, , nan, nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, $ 1,440,951, nan, nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, , nan, nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, $ 1,449,071, nan, nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, , nan, nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, $ 4,436,640, nan, nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, , nan, nan, nan, nan, nan, nan, nan)]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the list into a DataFrame\n",
    "df = pd.DataFrame(table[1:], columns=table[0])\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(in millions except per share data)', \"Q2 '10\", \"Q3 '10\", \"Q4 '10\", \"Q1 '11\", \"Q2 '11\", \"Q3 '11\", \"Q4 '11\", \"Q1 '12\"]\n",
      "['Domestic Streaming:', '', '', '', '', '', '', '', 'G id']\n",
      "['Net Subscription Additions', '-', '-', '-', '-', '-', '-', '0.22', '1.74']\n",
      "['Total Subscriptions', '-', '-', '-', '-', '-', '21.45', '21.67', '23.41']\n",
      "['Paid Subscriptions', '-', '-', '-', '-', '-', '20.51', '20.15', '22.02']\n",
      "['Revenue', '-', '-', '-', '-', '-', '-', '$ 476', '$ 507']\n",
      "['Contribution Profit', '-', '-', '-', '-', '-', '-', '$ 52', '$ 67']\n",
      "['Contribution Margin', '-', '-', '-', '-', '-', '-', '10.9%', '13.2%']\n",
      "['', '', '', '', '', '', '', '', '']\n",
      "['International Streaming:', '', '', '', '', '', '', '', '']\n",
      "['Net Subscription Additions', '-', '0.13', '0.38', '0.29', '0.16', '0.51', '0.38', '1.21']\n",
      "['Total Subscriptions', '-', '0.13', '0.51', '0.80', '0.97', '1.48', '1.86', '3.07']\n",
      "['Paid Subscriptions', '-', '-', '0.33', '0.67', '0.86', '0.99', '1.45', '2.41']\n",
      "['Revenue', '-', '$ -', '$ 4', '$ 12', '$ 19', '$ 23', '$ 29', '$ 43']\n",
      "['Contribution Profit (Loss)', '-', '$ (3)', '$ (9)', '$ (11)', '$ (9)', '$ (23)', '$ (60)', '$ (103)']\n",
      "['', '', '', '', '', '', '', '', '']\n",
      "['Domestic DVD:', '', '', '', '', '', '', '', '']\n",
      "['Net Subscription Additions', '-', '-', '-', '-', '-', '-', '(2.76)', '(1.08)']\n",
      "['Total Subscriptions', '-', '-', '-', '-', '-', '13.93', '11.17', '10.09']\n",
      "['Paid Subscriptions', '-', '-', '-', '-', '-', '13.81', '11.04', '9.96']\n",
      "['Revenue', '-', '-', '-', '-', '-', '-', '$ 370', '$ 320']\n",
      "['Contribution Profit', '-', '-', '-', '-', '-', '-', '$ 194', '$ 146']\n",
      "['Contribution Margin', '-', '-', '-', '-', '-', '-', '52.4%', '45.6%']\n",
      "['', '', '', '', '', '', '', '', '']\n",
      "['Total Domestic (Streaming + DVD, for historical comparison):', None, None, '', '', '', '', '', '']\n",
      "['Revenue', '$ 520', '$ 553', '$ 592', '$ 706', '$ 770', '$ 799', '$ 847', '$ 826']\n",
      "['Y/Y Change', '27%', '31%', '33%', '43%', '48%', '44%', '43%', '17%']\n",
      "['Contribution Profit', '$ 130', '$ 130', '$ 152', '$ 187', '$ 213', '$ 219', '$ 246', '$ 213']\n",
      "['Y/Y Change', '40%', '46%', '55%', '68%', '64%', '68%', '62%', '14%']\n",
      "['', '', '', '', '', '', '', '', '']\n",
      "['Global:', '', '', '', '', '', '', '', '']\n",
      "['Revenue', '$ 520', '$ 553', '$ 596', '$ 719', '$ 789', '$ 822', '$ 876', '$ 870']\n",
      "['Y/Y Change', '27%', '31%', '34%', '46%', '52%', '49%', '47%', '21%']\n",
      "['Net Income (Loss)', '$ 44', '$ 38', '$ 47', '$ 60', '$ 68', '$ 62', '$ 35', '$ (5)']\n",
      "['Y/Y Change', '38%', '27%', '52%', '88%', '55%', '63%', '-26%', 'NM']\n",
      "['EPS', '$ 0.80', '$ 0.70', '$ 0.87', '$ 1.11', '$ 1.26', '$ 1.16', '$ 0.64', '$ (0.08)']\n",
      "['Y/Y Change', '48%', '35%', '55%', '88%', '58%', '66%', '-26%', 'NM']\n",
      "['', '', '', '', '', '', '', '', '']\n",
      "['Free Cash Flow', '$ 34', '$ 8', '$ 51', '$ 79', '$ 60', '$ 14', '$ 34', '$ 2']\n",
      "['Buyback', '$ 45', '$ 57', '$ -', '$ 109', '$ 51', '$ 40', '$ -', '$ -']\n",
      "['Shares (FD)', '54.3', '53.9', '54.2', '54.2', '53.9', '53.9', '55.4', '55.5']\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "pdf_document = \"ShareholderLetters/Investor-Letter-Q1-2012.pdf\"\n",
    "page_number = 0  # Replace with the page number you're interested in\n",
    "\n",
    "with pdfplumber.open(pdf_document) as pdf:\n",
    "    page = pdf.pages[page_number]\n",
    "    \n",
    "    # Extract tables as DataFrame objects\n",
    "    tables = page.extract_tables()\n",
    "    \n",
    "    # Process the tables\n",
    "    for table in tables:\n",
    "        for row in table:\n",
    "            print(row)\n",
    "        print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n \\n1 \\nApril 23rd, 2012    \\nDear Fellow Shareholders, \\nNetflix added nearly 3 million streaming members in Q1, bringing our total to over 26 million global \\nstreaming members, and strengthening our position as the world’s leading Internet TV network.   We \\nanticipate returning to global profitability in Q2, and plan to launch our next international market in Q4.   \\nWe are constantly improving our service with better personalization, better user-interfaces, better \\nstreaming, and more content.  As a result, per-member viewing hours set new records in Q1 and are on \\ntrack to do so again in Q2, on a year-over-year basis.  We launched our service in the UK and Ireland in \\nJanuary and are very pleased that, after the first 90 days, we had substantially more members than we \\nhad after the first 90 days of Canada or Latin America.       \\n \\n (in millions except per share data)\\nQ2 '10\\nQ3 '10\\nQ4 '10\\nQ1 '11\\nQ2 '11\\nQ3 '11\\nQ4 '11\\nQ1 '12 \\nG id\\n \\nDomestic Streaming:\\nNet Subscription Additions\\n -  \\n -  \\n -  \\n -  \\n -  \\n -  \\n0.22\\n1.74\\nTotal Subscriptions\\n -  \\n -  \\n -  \\n -  \\n -  \\n21.45\\n21.67\\n23.41\\nPaid Subscriptions\\n -  \\n -  \\n -  \\n -  \\n -  \\n20.51\\n20.15\\n22.02\\nRevenue\\n -  \\n -  \\n -  \\n -  \\n -  \\n -   $       476  $       507 \\nContribution Profit\\n -  \\n -  \\n -  \\n -  \\n -  \\n -   $         52  $         67 \\nContribution Margin\\n -  \\n -  \\n -  \\n -  \\n -  \\n -  \\n10.9%\\n13.2%\\nInternational Streaming:\\nNet Subscription Additions\\n -  \\n0.13\\n0.38\\n0.29\\n0.16\\n0.51\\n0.38\\n1.21\\nTotal Subscriptions\\n -  \\n0.13\\n0.51\\n0.80\\n0.97\\n1.48\\n1.86\\n3.07\\nPaid Subscriptions\\n -  \\n -  \\n0.33\\n0.67\\n0.86\\n0.99\\n1.45\\n2.41\\nRevenue\\n -   $          -    $           4  $         12  $         19  $         23  $         29  $         43 \\nContribution Profit (Loss)\\n -   $          (3)  $          (9)  $        (11)  $          (9)  $        (23)  $        (60)  $      (103)\\nDomestic DVD:\\nNet Subscription Additions\\n -  \\n -  \\n -  \\n -  \\n -  \\n -  \\n(2.76)\\n(1.08)\\nTotal Subscriptions\\n -  \\n -  \\n -  \\n -  \\n -  \\n13.93\\n11.17\\n10.09\\nPaid Subscriptions\\n -  \\n -  \\n -  \\n -  \\n -  \\n13.81\\n11.04\\n9.96\\nRevenue\\n -  \\n -  \\n -  \\n -  \\n -  \\n -   $       370  $       320 \\nContribution Profit\\n -  \\n -  \\n -  \\n -  \\n -  \\n -   $       194  $       146 \\nContribution Margin\\n -  \\n -  \\n -  \\n -  \\n -  \\n -  \\n52.4%\\n45.6%\\nTotal Domestic (Streaming + DVD, for historical comparison):\\nRevenue\\n $       520  $       553  $       592  $       706  $       770  $       799  $       847  $       826 \\nY/Y Change\\n27%\\n31%\\n33%\\n43%\\n48%\\n44%\\n43%\\n17%\\nContribution Profit\\n $       130  $       130  $       152  $       187  $       213  $       219  $       246  $       213 \\nY/Y Change\\n40%\\n46%\\n55%\\n68%\\n64%\\n68%\\n62%\\n14%\\nGlobal:\\nRevenue\\n $       520  $       553  $       596  $       719  $       789  $       822  $       876  $       870 \\nY/Y Change\\n27%\\n31%\\n34%\\n46%\\n52%\\n49%\\n47%\\n21%\\nNet Income (Loss)\\n $         44  $         38  $         47  $         60  $         68  $         62  $         35  $          (5)\\nY/Y Change\\n38%\\n27%\\n52%\\n88%\\n55%\\n63%\\n-26%\\nNM\\nEPS\\n $      0.80  $      0.70  $      0.87  $      1.11  $      1.26  $      1.16  $      0.64  $     (0.08)\\nY/Y Change\\n48%\\n35%\\n55%\\n88%\\n58%\\n66%\\n-26%\\nNM\\nFree Cash Flow\\n $         34  $           8  $         51  $         79  $         60  $         14  $         34  $           2 \\nBuyback\\n $         45  $         57 \\n $          -    $       109  $         51  $         40 \\n $          -    $          -   \\nShares (FD)\\n54.3\\n53.9\\n54.2\\n54.2\\n53.9\\n53.9\\n55.4\\n55.5\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table detected on the page.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import fitz\n",
    "\n",
    "pdf_document = \"ShareholderLetters/Investor-Letter-Q1-2012.pdf\"\n",
    "page_number = 0  # Replace with the page number you're interested in\n",
    "\n",
    "doc = fitz.open(pdf_document)\n",
    "page = doc[page_number]\n",
    "\n",
    "text = page.get_text()\n",
    "\n",
    "# Define regular expressions for tabular data\n",
    "row_pattern = re.compile(r'\\n.*\\n')  # Match rows based on newline\n",
    "column_pattern = re.compile(r'\\s+')  # Match columns based on whitespace\n",
    "\n",
    "rows = row_pattern.findall(text)\n",
    "table_detected = False\n",
    "\n",
    "# Check if tabular data is detected\n",
    "if len(rows) > 1:\n",
    "    columns = column_pattern.split(rows[0])\n",
    "    if len(columns) > 1:\n",
    "        table_detected = True\n",
    "\n",
    "if table_detected:\n",
    "    print(\"Table detected on the page.\")\n",
    "else:\n",
    "    print(\"No table detected on the page.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean the data\n",
    "def clean_data(df):\n",
    "    # Create a dictionary to store the values\n",
    "    new_df = {\"label\": [], \"text\": []}\n",
    "\n",
    "    # Iterate over all rows in the dataset\n",
    "    for row in tqdm(range(len(df.loc[:, \"text\"].to_list()))):\n",
    "        # Initialize temporary array to store tokens\n",
    "        tmp_tokens = []\n",
    "\n",
    "        try:\n",
    "            # # Check whether the review is written in English or not\n",
    "            # if langdetect.detect(df.loc[row, \"text\"]) == \"en\" or True:\n",
    "                for token in nlp(df.loc[row, \"text\"]):\n",
    "                    # Set conditions to retain valuable information\n",
    "                    if (\n",
    "                        not token.is_stop  # remove stop-words\n",
    "                        and not token.is_punct  # remove punctuation\n",
    "                        and not token.like_num  # remove numbers\n",
    "                        and token.is_oov  # remove words that don't have a word vector\n",
    "                        and not token.is_space  # remove whitespaces\n",
    "                        and len(token) > 1  # remove single-letter words\n",
    "                        # Remove tokens that looks weird & not useful\n",
    "                        and not str(token).endswith(\"-\")\n",
    "                        and not str(token).endswith(\".\")\n",
    "                        and not any(\n",
    "                            substr in str(token)\n",
    "                            for substr in [\n",
    "                                \"---\",\n",
    "                                \"--\",\n",
    "                                \"/2\",\n",
    "                                \"/1\",\n",
    "                                \"20feb\",\n",
    "                                \"c17\",\n",
    "                                \"\\x92\",\n",
    "                                \"&\",\n",
    "                                \"%\",\n",
    "                                \"i.e.\",\n",
    "                                \"b+\",\n",
    "                                \"w/\",\n",
    "                                \"02:33:05\",\n",
    "                            ]\n",
    "                        )\n",
    "                        and not str(token).startswith(\"-\")\n",
    "                    ):\n",
    "                        # Get the lemma & lowercase the token\n",
    "                        token = token.lemma_.lower()\n",
    "                        if \"(\" in token:\n",
    "                            token = token.split(\"(\")\n",
    "                            tmp_tokens.append(token[0])\n",
    "                            tmp_tokens.append(token[1])\n",
    "                        elif token == \"orangy/\":\n",
    "                            token = \"orangy\"\n",
    "                        elif token == \".fruity\":\n",
    "                            token = \"fruity\"\n",
    "\n",
    "                        tmp_tokens.append(token)\n",
    "\n",
    "                # Append the corresponding label to the review\n",
    "                new_df[\"label\"].append(df.loc[row, \"label\"])\n",
    "\n",
    "                # Add all tokens from the review to the text\n",
    "                new_df[\"text\"].append(tmp_tokens)\n",
    "                # Reset the token array\n",
    "                tmp_tokens = []\n",
    "        except:\n",
    "            continue  # proceed to next row if an exception is raised\n",
    "        \n",
    "    # Return the new dataframe\n",
    "    return pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
