{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3266411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import tempfile\n",
    "import pdfplumber\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3dda9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_agent = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024c999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ChromeOptions instance to set user agent\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(f\"--user-agent={user_agent}\")\n",
    "\n",
    "# Create a new instance of Chrome web browser using ChromeDriverManager\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# Navigate to the desired URL\n",
    "url = \"https://www.ft.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load (you might need to adjust the waiting time)\n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9850e32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the \"Accept cookies\" button element using its XPath\n",
    "accept_cookies_button = WebDriverWait(driver, 20).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//a[@data-n-messaging-accept-cookies]\"))\n",
    ")\n",
    "\n",
    "# Click the \"Accept cookies\" button\n",
    "accept_cookies_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d63af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the \"Sign In\" link element using its text\n",
    "sign_in_link = WebDriverWait(driver, 20).until(\n",
    "    EC.element_to_be_clickable((By.LINK_TEXT, \"Sign In\"))\n",
    ")\n",
    "\n",
    "# Click the \"Sign In\" link\n",
    "sign_in_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a0825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the email input element by its ID\n",
    "email_input = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.ID, \"enter-email\"))\n",
    ")\n",
    "\n",
    "# Clear any existing text in the input field (optional, based on your use case)\n",
    "email_input.clear()\n",
    "\n",
    "# Enter the email address into the input field\n",
    "email_address = \"xxx@bayes.city.ac.uk\"  # Replace with the actual email address\n",
    "email_input.send_keys(email_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49abcdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the \"Next\" button element by its ID\n",
    "next_button = WebDriverWait(driver, 20).until(\n",
    "    EC.element_to_be_clickable((By.ID, \"enter-email-next\"))\n",
    ")\n",
    "\n",
    "# Click the \"Next\" button\n",
    "next_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "138b312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the \"SSO Sign in\" link element by its href attribute\n",
    "sso_sign_in_link = WebDriverWait(driver, 20).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//a[contains(@href, 'sso.ft.com')]\"))\n",
    ")\n",
    "\n",
    "# Click the \"SSO Sign in\" link\n",
    "sso_sign_in_link.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5ad20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the email input element by its ID\n",
    "email_input = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.ID, \"userNameInput\"))\n",
    ")\n",
    "\n",
    "# Enter the email address into the email input field\n",
    "email_address = \"xxx@bayes.city.ac.uk\"  # Replace with the actual email address\n",
    "email_input.send_keys(email_address)\n",
    "\n",
    "# Find the password input element by its ID\n",
    "password_input = driver.find_element(By.ID, \"passwordInput\")\n",
    "\n",
    "# Enter the password into the password input field\n",
    "password = \"xxxx\"  # Replace with the actual password\n",
    "password_input.send_keys(password)\n",
    "\n",
    "# Find the \"Sign in\" span element by its ID\n",
    "sign_in_button = driver.find_element(By.ID, \"submitButton\")\n",
    "\n",
    "# Click the \"Sign in\" span element\n",
    "sign_in_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca400676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the search button element\n",
    "search_button = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//a[contains(@class, 'o-header__top-icon-link--search')]\"))\n",
    ")\n",
    "\n",
    "# Scroll to the search button element\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", search_button)\n",
    "\n",
    "# Simulate a click using JavaScript\n",
    "driver.execute_script(\"arguments[0].click();\", search_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcaed0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the search input element\n",
    "search_input = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//input[@id='o-header-search-term-primary']\"))\n",
    ")\n",
    "\n",
    "# Clear any existing text and type \"nflx\"\n",
    "search_input.clear()\n",
    "search_input.send_keys(\"netflix inc\")\n",
    "\n",
    "# Find the search button element\n",
    "search_button = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//button[@class='o-header__search-submit']\"))\n",
    ")\n",
    "\n",
    "# Click the search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9283e9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.ft.com/content/4ae74277-6176-488c-995d-b92e96d3737f', 'https://www.ft.com/content/62efe7f4-5a87-413e-962e-6c5cb3e82b5e', 'https://www.ft.com/content/1156111a-4a77-40cd-9338-bd853e8956fb', 'https://www.ft.com/content/fb270603-8ca0-42da-8157-c9efcdb2e7fe', 'https://www.ft.com/content/4a9df0bd-df9d-45a7-b407-428ca8b64e7f', 'https://www.ft.com/content/cae01c41-2e09-418c-a381-a03f7018f31f', 'https://www.ft.com/content/6c76b102-d012-4abd-96d7-54124f7235ef', 'https://www.ft.com/content/fda9fa7b-3a4c-4a16-b384-7867b0974074', 'https://www.ft.com/content/5bdee38f-037c-4c15-9009-2e4c829c08a2']\n"
     ]
    }
   ],
   "source": [
    "# Wait for the search results to load\n",
    "WebDriverWait(driver, 5).until(\n",
    "    EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    ")\n",
    "\n",
    "# Find all the teaser elements\n",
    "teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")\n",
    "\n",
    "# Create an empty list to store the URLs\n",
    "netflix_articles = []\n",
    "\n",
    "# Loop through the teaser elements\n",
    "for teaser in teaser_elements:\n",
    "    heading_element = teaser.find_element(By.CLASS_NAME, \"o-teaser__heading\")\n",
    "    heading_text = heading_element.text.lower()  # Convert to lowercase for case-insensitive comparison\n",
    "    if \"netflix\" in heading_text:\n",
    "        link_element = heading_element.find_element(By.TAG_NAME, \"a\")\n",
    "        article_url = link_element.get_attribute(\"href\")\n",
    "        netflix_articles.append(article_url)\n",
    "\n",
    "# Print the list of URLs\n",
    "print(netflix_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5318c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the URLs\n",
    "netflix_articles = []\n",
    "\n",
    "while True:\n",
    "    # Wait for the search results to load\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    "    )\n",
    "\n",
    "    # Find all the teaser elements\n",
    "    teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")\n",
    "\n",
    "    # Loop through the teaser elements\n",
    "    for teaser in teaser_elements:\n",
    "        heading_element = teaser.find_element(By.CLASS_NAME, \"o-teaser__heading\")\n",
    "        heading_text = heading_element.text.lower()  # Convert to lowercase for case-insensitive comparison\n",
    "        if \"netflix\" in heading_text:\n",
    "            link_element = heading_element.find_element(By.TAG_NAME, \"a\")\n",
    "            article_url = link_element.get_attribute(\"href\")\n",
    "            netflix_articles.append(article_url)\n",
    "\n",
    "    # Check if the \"Sorry, FT.com does not serve more than 1000 results\" message is present\n",
    "    error_message = \"Sorry, FT.com does not serve more than 1000 results\"\n",
    "    if error_message in driver.page_source:\n",
    "        break\n",
    "\n",
    "    # Click the \"Next page\" arrow to load the next page\n",
    "    next_page_arrow = driver.find_element(By.CSS_SELECTOR, \".search-pagination__next-page\")\n",
    "    next_page_arrow.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create an empty list to store the URLs\n",
    "len(netflix_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1b2e794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ft.com/content/dc79eecf-ed3c-486a-8b89-60c67b6ff10a'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the URL of the first news article\n",
    "first_url = netflix_articles[0]\n",
    "first_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f746853",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# URL to the article\n",
    "url = 'https://www.ft.com/content/dc79eecf-ed3c-486a-8b89-60c67b6ff10a'\n",
    "\n",
    "# Open the URL using the WebDriver\n",
    "driver.get(url)\n",
    "\n",
    "# Get the page source (HTML content) after it's fully loaded\n",
    "page_source = driver.page_source\n",
    "\n",
    "\n",
    "# Parse the page source using BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8b39557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daniel Thomas\n",
      "Netflix to revamp advertising strategy to lure brands and boost revenues\n"
     ]
    }
   ],
   "source": [
    "# Find the author's link\n",
    "author_link = soup.find(\"a\", class_=\"n-content-tag--author\")\n",
    "\n",
    "# Extract and print the author's name\n",
    "author_name = author_link.text\n",
    "print(author_name)\n",
    "\n",
    "# Find the heading element\n",
    "heading_element = soup.find(\"h1\", class_=\"o-topper__headline\")\n",
    "\n",
    "# Find the inner span element within the heading element\n",
    "span_element = heading_element.find(\"span\", class_=\"article-classifier__gap\")\n",
    "\n",
    "# Extract and print the heading text\n",
    "heading = span_element.text\n",
    "print(heading)\n",
    "\n",
    "# Find the timestamp element\n",
    "timestamp_element = soup.find(\"time\", class_=\"article-info__timestamp\")\n",
    "\n",
    "# Extract and print the timestamp\n",
    "timestamp = timestamp_element['datetime']\n",
    "date, time = timestamp.split('T')\n",
    "print(\"Date:\", date)\n",
    "print(\"Time:\", time[:-5])  # Remove the milliseconds and 'Z'\n",
    "\n",
    "# Find the article content element\n",
    "article_content_element = soup.find(\"div\", class_=\"article__content-body\")\n",
    "\n",
    "# Extract and print the full article text\n",
    "article_text = \"\"\n",
    "for paragraph in article_content_element.find_all(\"p\"):\n",
    "    article_text += paragraph.get_text() + \"\\n\"\n",
    "\n",
    "print(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d1c36ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the scraped data\n",
    "scraped_data = []\n",
    "error_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8c00cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through the URLs\n",
    "for url in netflix_articles:\n",
    "    try:\n",
    "        # Open the URL using ChromeDriver\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Get the page source after waiting for a bit to ensure it's fully loaded\n",
    "        driver.implicitly_wait(5)\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        # Parse the page source using Beautiful Soup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        # Find the author's link\n",
    "        try:\n",
    "            author_link = soup.find(\"a\", class_=\"n-content-tag--author\")\n",
    "            author_name = author_link.text if author_link else \"Unknown Author\"\n",
    "        except Exception as author_err:\n",
    "            author_name = \"Error extracting author\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Author\", \"error\": str(author_err)})\n",
    "        \n",
    "        # Find the heading element\n",
    "        try:\n",
    "            heading_element = soup.find(\"h1\", class_=\"o-topper__headline\")\n",
    "            heading = heading_element.text if heading_element else \"Unknown Heading\"\n",
    "        except Exception as heading_err:\n",
    "            heading = \"Error extracting heading\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Heading\", \"error\": str(heading_err)})\n",
    "        \n",
    "        # Find the timestamp element\n",
    "        try:\n",
    "            timestamp_element = soup.find(\"time\", class_=\"article-info__timestamp\")\n",
    "            timestamp = timestamp_element['datetime'] if timestamp_element else \"Unknown Timestamp\"\n",
    "            date, time = timestamp.split('T')\n",
    "        except Exception as timestamp_err:\n",
    "            date = \"Unknown Date\"\n",
    "            time = \"Unknown Time\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Timestamp\", \"error\": str(timestamp_err)})\n",
    "        \n",
    "        # Find the article content element\n",
    "        try:\n",
    "            article_content_element = soup.find(\"div\", class_=\"article__content-body\")\n",
    "            \n",
    "            # Extract the full article text\n",
    "            article_text = \"\"\n",
    "            for paragraph in article_content_element.find_all(\"p\"):\n",
    "                article_text += paragraph.get_text() + \"\\n\"\n",
    "        except Exception as article_err:\n",
    "            article_text = \"Error extracting article text\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Article\", \"error\": str(article_err)})\n",
    "        \n",
    "        # Store the scraped data in a dictionary\n",
    "        scraped_data.append({\n",
    "            \"url\": url,\n",
    "            \"author\": author_name,\n",
    "            \"heading\": heading,\n",
    "            \"date\": date,\n",
    "            \"time\": time[:-5],\n",
    "            \"article_text\": article_text\n",
    "        })\n",
    "    \n",
    "    except Exception as page_err:\n",
    "        error_log.append({\"url\": url, \"field\": \"Page\", \"error\": str(page_err)})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5493adab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2a973404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.DataFrame(scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "64a7d57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   url           299 non-null    object\n",
      " 1   author        299 non-null    object\n",
      " 2   heading       299 non-null    object\n",
      " 3   date          299 non-null    object\n",
      " 4   time          299 non-null    object\n",
      " 5   article_text  299 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 14.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ff9b38f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ft.com/content/dc79eecf-ed3c-486a-...</td>\n",
       "      <td>Daniel Thomas</td>\n",
       "      <td>Netflix to revamp advertising strategy to lure...</td>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>04:00:10</td>\n",
       "      <td>Netflix will develop increasingly targeted and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ft.com/content/6c76b102-d012-4abd-...</td>\n",
       "      <td>Unknown Author</td>\n",
       "      <td>Netflix: password sharing cutback provides sho...</td>\n",
       "      <td>2023-07-20</td>\n",
       "      <td>10:36:06</td>\n",
       "      <td>Offering the same service at higher prices sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ft.com/content/fda9fa7b-3a4c-4a16-...</td>\n",
       "      <td>Anna Nicolaou</td>\n",
       "      <td>Netflix’s password-sharing crackdown pays off ...</td>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>21:37:20</td>\n",
       "      <td>A crackdown on password sharing helped Netflix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ft.com/content/64279611-9c8e-4ee5-...</td>\n",
       "      <td>Moira O’Neill</td>\n",
       "      <td>Can Netflix really teach us ‘how to get rich’?</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>09:56:15</td>\n",
       "      <td>The cost of living crisis and inflation are to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ft.com/content/a85f2d38-1889-4108-...</td>\n",
       "      <td>Christopher Grimes</td>\n",
       "      <td>Netflix is taking a necessary risk in tackling...</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>04:00:49</td>\n",
       "      <td>When Netflix co-founder Reed Hastings declared...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url              author  \\\n",
       "0  https://www.ft.com/content/dc79eecf-ed3c-486a-...       Daniel Thomas   \n",
       "1  https://www.ft.com/content/6c76b102-d012-4abd-...      Unknown Author   \n",
       "2  https://www.ft.com/content/fda9fa7b-3a4c-4a16-...       Anna Nicolaou   \n",
       "3  https://www.ft.com/content/64279611-9c8e-4ee5-...       Moira O’Neill   \n",
       "4  https://www.ft.com/content/a85f2d38-1889-4108-...  Christopher Grimes   \n",
       "\n",
       "                                             heading        date      time  \\\n",
       "0  Netflix to revamp advertising strategy to lure...  2023-07-03  04:00:10   \n",
       "1  Netflix: password sharing cutback provides sho...  2023-07-20  10:36:06   \n",
       "2  Netflix’s password-sharing crackdown pays off ...  2023-07-19  21:37:20   \n",
       "3     Can Netflix really teach us ‘how to get rich’?  2023-05-12  09:56:15   \n",
       "4  Netflix is taking a necessary risk in tackling...  2023-05-26  04:00:49   \n",
       "\n",
       "                                        article_text  \n",
       "0  Netflix will develop increasingly targeted and...  \n",
       "1  Offering the same service at higher prices sug...  \n",
       "2  A crackdown on password sharing helped Netflix...  \n",
       "3  The cost of living crisis and inflation are to...  \n",
       "4  When Netflix co-founder Reed Hastings declared...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2ec4042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with problematic or incomplete data\n",
    "df_cleaned = df_new[\n",
    "    (df_new['author'] != 'Unknown Author') &\n",
    "    (df_new['heading'] != 'Unknown Heading') &\n",
    "    (df_new['date'] != 'Unknown') &\n",
    "    (df_new['time'] != 'ime')\n",
    "]\n",
    "\n",
    "df_cleaned = df_cleaned.copy()\n",
    "df_cleaned['date'] = pd.to_datetime(df_cleaned['date'])\n",
    "\n",
    "\n",
    "# Sort the DataFrame by the 'date' column in descending order\n",
    "df_sorted = df_cleaned.sort_values(by='date', ascending=False)\n",
    "\n",
    "# Print the cleaned and sorted DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "41d5dd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>https://www.ft.com/content/e9d7e4de-b2b6-11e7-...</td>\n",
       "      <td>Tim Bradshaw</td>\n",
       "      <td>Netflix subscriber growth tops estimates</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>00:02:17</td>\n",
       "      <td>Netflix attracted more new subscribers than ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>https://www.ft.com/content/56fb3b11-a23a-3f60-...</td>\n",
       "      <td>Tim Bradshaw</td>\n",
       "      <td>Netflix subscriber growth tops estimates, reve...</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>20:46:47</td>\n",
       "      <td>Netflix posted a 30 per cent jump in revenue t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>https://www.ft.com/content/48c368c1-606b-3859-...</td>\n",
       "      <td>Tim Bradshaw</td>\n",
       "      <td>Netflix rules out bid for Weinstein Company</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>22:52:33</td>\n",
       "      <td>Netflix has effectively ruled itself out of bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>https://www.ft.com/content/e6679a36-bfc2-3ac0-...</td>\n",
       "      <td>Pan Kwan Yuk</td>\n",
       "      <td>Netflix climbs past $200 for first time after ...</td>\n",
       "      <td>2017-10-13</td>\n",
       "      <td>15:07:57</td>\n",
       "      <td>Shares in Netflix briefly crossed the $200 mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>https://www.ft.com/content/10ec51db-104d-37c6-...</td>\n",
       "      <td>Jessica Dye</td>\n",
       "      <td>Netflix shares zip higher on subscription pric...</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>15:36:57</td>\n",
       "      <td>Investors are tuning into Netflix after the vi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url        author  \\\n",
       "297  https://www.ft.com/content/e9d7e4de-b2b6-11e7-...  Tim Bradshaw   \n",
       "288  https://www.ft.com/content/56fb3b11-a23a-3f60-...  Tim Bradshaw   \n",
       "291  https://www.ft.com/content/48c368c1-606b-3859-...  Tim Bradshaw   \n",
       "296  https://www.ft.com/content/e6679a36-bfc2-3ac0-...  Pan Kwan Yuk   \n",
       "292  https://www.ft.com/content/10ec51db-104d-37c6-...   Jessica Dye   \n",
       "\n",
       "                                               heading       date      time  \\\n",
       "297           Netflix subscriber growth tops estimates 2017-10-17  00:02:17   \n",
       "288  Netflix subscriber growth tops estimates, reve... 2017-10-16  20:46:47   \n",
       "291        Netflix rules out bid for Weinstein Company 2017-10-16  22:52:33   \n",
       "296  Netflix climbs past $200 for first time after ... 2017-10-13  15:07:57   \n",
       "292  Netflix shares zip higher on subscription pric... 2017-10-05  15:36:57   \n",
       "\n",
       "                                          article_text  \n",
       "297  Netflix attracted more new subscribers than ex...  \n",
       "288  Netflix posted a 30 per cent jump in revenue t...  \n",
       "291  Netflix has effectively ruled itself out of bi...  \n",
       "296  Shares in Netflix briefly crossed the $200 mar...  \n",
       "292  Investors are tuning into Netflix after the vi...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cfd452ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ft.com/content/fda9fa7b-3a4c-4a16-...</td>\n",
       "      <td>Anna Nicolaou</td>\n",
       "      <td>Netflix’s password-sharing crackdown pays off ...</td>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>21:37:20</td>\n",
       "      <td>A crackdown on password sharing helped Netflix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.ft.com/content/1cc91834-ef81-4a5d-...</td>\n",
       "      <td>Akito Tanaka</td>\n",
       "      <td>US tech can’t quit China and Netflix dives int...</td>\n",
       "      <td>2023-07-13</td>\n",
       "      <td>07:26:38</td>\n",
       "      <td>Hello everyone, this is Akito from Singapore.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ft.com/content/dc79eecf-ed3c-486a-...</td>\n",
       "      <td>Daniel Thomas</td>\n",
       "      <td>Netflix to revamp advertising strategy to lure...</td>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>04:00:10</td>\n",
       "      <td>Netflix will develop increasingly targeted and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ft.com/content/a85f2d38-1889-4108-...</td>\n",
       "      <td>Christopher Grimes</td>\n",
       "      <td>Netflix is taking a necessary risk in tackling...</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>04:00:49</td>\n",
       "      <td>When Netflix co-founder Reed Hastings declared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ft.com/content/13f719af-b406-4c53-...</td>\n",
       "      <td>Daniel Thomas</td>\n",
       "      <td>Netflix alerts telecoms groups over looming ac...</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>10:00:32</td>\n",
       "      <td>Netflix has held talks with UK telecoms groups...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url              author  \\\n",
       "2  https://www.ft.com/content/fda9fa7b-3a4c-4a16-...       Anna Nicolaou   \n",
       "6  https://www.ft.com/content/1cc91834-ef81-4a5d-...        Akito Tanaka   \n",
       "0  https://www.ft.com/content/dc79eecf-ed3c-486a-...       Daniel Thomas   \n",
       "4  https://www.ft.com/content/a85f2d38-1889-4108-...  Christopher Grimes   \n",
       "5  https://www.ft.com/content/13f719af-b406-4c53-...       Daniel Thomas   \n",
       "\n",
       "                                             heading       date      time  \\\n",
       "2  Netflix’s password-sharing crackdown pays off ... 2023-07-19  21:37:20   \n",
       "6  US tech can’t quit China and Netflix dives int... 2023-07-13  07:26:38   \n",
       "0  Netflix to revamp advertising strategy to lure... 2023-07-03  04:00:10   \n",
       "4  Netflix is taking a necessary risk in tackling... 2023-05-26  04:00:49   \n",
       "5  Netflix alerts telecoms groups over looming ac... 2023-05-16  10:00:32   \n",
       "\n",
       "                                        article_text  \n",
       "2  A crackdown on password sharing helped Netflix...  \n",
       "6  Hello everyone, this is Akito from Singapore.\\...  \n",
       "0  Netflix will develop increasingly targeted and...  \n",
       "4  When Netflix co-founder Reed Hastings declared...  \n",
       "5  Netflix has held talks with UK telecoms groups...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09301e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv('ft_articles_2023_07_19_to_2017_10_05.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ea1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "af78b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the search button element\n",
    "search_button = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//a[contains(@class, 'o-header__top-icon-link--search')]\"))\n",
    ")\n",
    "\n",
    "# Scroll to the search button element\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", search_button)\n",
    "\n",
    "\n",
    "# Simulate a click using JavaScript\n",
    "driver.execute_script(\"arguments[0].click();\", search_button)\n",
    "# Find the search input element\n",
    "search_input = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//input[@id='o-header-search-term-primary']\"))\n",
    ")\n",
    "\n",
    "# Clear any existing text and type \n",
    "search_input.clear()\n",
    "search_input.send_keys(\"netflix quaterly result\")\n",
    "\n",
    "# Find the search button element\n",
    "search_button = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//button[@class='o-header__search-submit']\"))\n",
    ")\n",
    "\n",
    "# Click the search button\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ed9f3e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "957\n"
     ]
    }
   ],
   "source": [
    "# Define regular expressions to match unwanted tags\n",
    "unwanted_tag_patterns = [\n",
    "    re.compile(r'^live news updates from', re.IGNORECASE),\n",
    "    re.compile(r'^transcript', re.IGNORECASE),\n",
    "    re.compile(r'news updates from', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "# Create an empty list to store the article URLs\n",
    "netflix_article_urls = []\n",
    "\n",
    "while True:\n",
    "    # Wait for the search results to load\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    "    )\n",
    "\n",
    "    # Find all the teaser elements\n",
    "    teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")\n",
    "\n",
    "    # Loop through the teaser elements and store the article URLs\n",
    "    for teaser in teaser_elements:\n",
    "        tag_elements = teaser.find_elements(By.CLASS_NAME, \"o-teaser__tag\")\n",
    "        tag_texts = [tag_element.text.lower() for tag_element in tag_elements]\n",
    "        \n",
    "        # Check if any of the tag texts match unwanted patterns\n",
    "        if not any(pattern.match(tag_text) for tag_text in tag_texts for pattern in unwanted_tag_patterns):\n",
    "            heading_element = teaser.find_element(By.CLASS_NAME, \"o-teaser__heading\")\n",
    "            link_element = heading_element.find_element(By.TAG_NAME, \"a\")\n",
    "            article_url = link_element.get_attribute(\"href\")\n",
    "            netflix_article_urls.append(article_url)\n",
    "\n",
    "    # Check if the \"Sorry, FT.com does not serve more than 1000 results\" message is present\n",
    "    error_message = \"Sorry, FT.com does not serve more than 1000 results\"\n",
    "    if error_message in driver.page_source:\n",
    "        break\n",
    "\n",
    "    # Click the \"Next page\" arrow to load the next page\n",
    "    next_page_arrow = driver.find_element(By.CSS_SELECTOR, \".search-pagination__next-page\")\n",
    "    next_page_arrow.click()\n",
    "\n",
    "# Print the number of collected article URLs\n",
    "print(len(netflix_article_urls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4acef847",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(netflix_article_urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "84452ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna Nicolaou\n",
      "Netflix’s password-sharing crackdown pays off with nearly 6mn new subscribers\n",
      "Date: 2023-07-19\n",
      "Time: 21:37:20\n",
      "A crackdown on password sharing helped Netflix add nearly 6mn subscribers, more than double what analysts had forecast and validating the streamer’s strategy to shore up its business.\n",
      "After shocking investors by losing subscribers last year, Netflix has responded with two big steps: introducing a cheaper version of its service with advertisements, and trying to limit password sharing, a practice it had largely ignored when growth was high.\n",
      "Netflix in May cracked down on password sharing for accounts in the US, UK and more than 100 other countries. In the US, Netflix has told customers that if they want to share their password, they must pay $7.99 a month to add a person outside their home, or $6.99 if they are prepared to have an account with adverts.\n",
      "That policy appears to be working. In the three months to the end of June, Netflix added 5.9mn subscribers, well above Wall Street expectations for 2mn. “The cancel reaction was low,” the company told investors on Wednesday. \n",
      "However, shares in Netflix, which had gained more than 8 per cent in the five days leading up to the earnings release, dropped more than 8 per cent in post-market trading after the company reported softer revenue. \n",
      "Netflix’s quarterly revenue rose to $8.2bn, up 3 per cent from a year ago but just short of forecasts for $8.3bn. The company predicted that revenue would climb to $8.5bn in the current quarter, missing analysts’ forecasts for $8.7bn. \n",
      "Netflix’s password crackdown reflects the harsh realities of the costly streaming model that it has pioneered. When Wall Street was more keen on streaming, investors looked past the heavy losses companies were enduring, so long as they were able to keep adding subscribers quickly. \n",
      "But as the wider market has cooled, investors are more focused on profits. Competition has heated up, with Disney and others vying with Netflix for customers.\n",
      "Recommended\n",
      "Netflix is profitable, while Disney+, Paramount+ and other rival streaming services are still losing money. Netflix on Wednesday reported quarterly net income of $1.5bn, up 3 per cent from the same period a year ago.\n",
      "The company said it would spend less money this year due to the historic labour strike in Hollywood, which has brought movie and television production in the US to a halt. Netflix now expects free cash flow of $5bn this year, up from its previous estimate of $3.5bn. \n",
      "Many workers have blamed Netflix for ushering in a streaming revolution that has made it difficult for screenwriters to make a decent living. On an earnings call, co-chief executive Ted Sarandos said the strike was “not an outcome that we wanted”, while highlighting his father’s ties to unions. \n",
      "“On a personal level, I was raised in a union household. My dad was a member of IBEW Local 640, he was a union electrician . . . I remember on more than one occasion my dad being out on strike, and I remember that because it takes an enormous toll on your family, financially and emotionally,” he said.\n",
      "Paolo Pescatore, analyst at PP Foresight, said the results were “a strong endorsement” of Netflix’s password strategy, but cautioned that the crackdown was a “short-term measure”. Netflix “needs to consider its pricing strategy for the mid to long term”, he said. \n",
      "After tumbling last year, Netflix shares have made a comeback in 2023, gaining more than 60 per cent.\n",
      "“While we’ve made steady progress this year, we have more work to do to reaccelerate our growth,” Netflix told shareholders in a letter.\n",
      "Highlight\n",
      "Remove highlight\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the page source (HTML content) after it's fully loaded\n",
    "page_source = driver.page_source\n",
    "\n",
    "\n",
    "# Parse the page source using BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "\n",
    "# Find the author's link\n",
    "author_link = soup.find(\"a\", class_=\"n-content-tag--author\")\n",
    "\n",
    "# Extract and print the author's name\n",
    "author_name = author_link.text\n",
    "print(author_name)\n",
    "\n",
    "# Find the heading element\n",
    "heading_element = soup.find(\"h1\", class_=\"o-topper__headline\")\n",
    "\n",
    "# Find the inner span element within the heading element\n",
    "span_element = heading_element.find(\"span\", class_=\"article-classifier__gap\")\n",
    "\n",
    "# Extract and print the heading text\n",
    "heading = span_element.text\n",
    "print(heading)\n",
    "\n",
    "# Find the timestamp element\n",
    "timestamp_element = soup.find(\"time\", class_=\"article-info__timestamp\")\n",
    "\n",
    "# Extract and print the timestamp\n",
    "timestamp = timestamp_element['datetime']\n",
    "date, time = timestamp.split('T')\n",
    "print(\"Date:\", date)\n",
    "print(\"Time:\", time[:-5])  # Remove the milliseconds and 'Z'\n",
    "\n",
    "# Find the article content element\n",
    "article_content_element = soup.find(\"div\", class_=\"article__content-body\")\n",
    "\n",
    "# Extract and print the full article text\n",
    "article_text = \"\"\n",
    "for paragraph in article_content_element.find_all(\"p\"):\n",
    "    article_text += paragraph.get_text() + \"\\n\"\n",
    "\n",
    "print(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "501d8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the scraped data\n",
    "scraped_data = []\n",
    "error_log = []\n",
    "\n",
    "\n",
    "\n",
    "# Loop through the URLs\n",
    "for url in netflix_article_urls:\n",
    "    try:\n",
    "        # Open the URL using ChromeDriver\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Get the page source after waiting for a bit to ensure it's fully loaded\n",
    "        driver.implicitly_wait(5)\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        # Parse the page source using Beautiful Soup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        # Find the author's link\n",
    "        try:\n",
    "            author_link = soup.find(\"a\", class_=\"n-content-tag--author\")\n",
    "            author_name = author_link.text if author_link else \"Unknown Author\"\n",
    "        except Exception as author_err:\n",
    "            author_name = \"Error extracting author\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Author\", \"error\": str(author_err)})\n",
    "        \n",
    "        # Find the heading element\n",
    "        try:\n",
    "            heading_element = soup.find(\"h1\", class_=\"o-topper__headline\")\n",
    "            heading = heading_element.text if heading_element else \"Unknown Heading\"\n",
    "        except Exception as heading_err:\n",
    "            heading = \"Error extracting heading\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Heading\", \"error\": str(heading_err)})\n",
    "        \n",
    "        # Find the timestamp element\n",
    "        try:\n",
    "            timestamp_element = soup.find(\"time\", class_=\"article-info__timestamp\")\n",
    "            timestamp = timestamp_element['datetime'] if timestamp_element else \"Unknown Timestamp\"\n",
    "            date, time = timestamp.split('T')\n",
    "        except Exception as timestamp_err:\n",
    "            date = \"Unknown Date\"\n",
    "            time = \"Unknown Time\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Timestamp\", \"error\": str(timestamp_err)})\n",
    "        \n",
    "        # Find the article content element\n",
    "        try:\n",
    "            article_content_element = soup.find(\"div\", class_=\"article__content-body\")\n",
    "            \n",
    "            # Extract the full article text\n",
    "            article_text = \"\"\n",
    "            for paragraph in article_content_element.find_all(\"p\"):\n",
    "                article_text += paragraph.get_text() + \"\\n\"\n",
    "        except Exception as article_err:\n",
    "            article_text = \"Error extracting article text\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Article\", \"error\": str(article_err)})\n",
    "        \n",
    "        # Store the scraped data in a dictionary\n",
    "        scraped_data.append({\n",
    "            \"url\": url,\n",
    "            \"author\": author_name,\n",
    "            \"heading\": heading,\n",
    "            \"date\": date,\n",
    "            \"time\": time[:-5],\n",
    "            \"article_text\": article_text\n",
    "        })\n",
    "    \n",
    "    except Exception as page_err:\n",
    "        error_log.append({\"url\": url, \"field\": \"Page\", \"error\": str(page_err)})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1=pd.DataFrame(scraped_data)\n",
    "\n",
    "# Remove rows with problematic or incomplete data\n",
    "df_cleaned_1 = df_new_1[\n",
    "    (df_new_1['author'] != 'Unknown Author') &\n",
    "    (df_new_1['heading'] != 'Unknown Heading') &\n",
    "    (df_new_1['date'] != 'Unknown') &\n",
    "    (df_new_1['time'] != 'ime')\n",
    "]\n",
    "\n",
    "df_cleaned_1 = df_cleaned_1.copy()\n",
    "df_cleaned_1['date'] = pd.to_datetime(df_cleaned_1['date'])\n",
    "\n",
    "\n",
    "# Sort the DataFrame by the 'date' column in descending order\n",
    "df_sorted_1 = df_cleaned_1.sort_values(by='date', ascending=False)\n",
    "\n",
    "# Print the cleaned and sorted DataFrame\n",
    "\n",
    "df_sorted_1.to_csv('ft_articles_05.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e911f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeceddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa9c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4adf1f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# Define regular expressions to match unwanted tags\n",
    "unwanted_tag_patterns = [\n",
    "    re.compile(r'^live news updates from', re.IGNORECASE),\n",
    "    re.compile(r'^transcript', re.IGNORECASE),\n",
    "    re.compile(r'news updates from', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "# Create an empty list to store the article data\n",
    "netflix_articles = []\n",
    "\n",
    "for x in range(2):\n",
    "    # Wait for the search results to load\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    "    )\n",
    "\n",
    "    # Find all the teaser elements\n",
    "    teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")\n",
    "\n",
    "    # Loop through the teaser elements and store the article data\n",
    "    for teaser in teaser_elements:\n",
    "        tag_elements = teaser.find_elements(By.CLASS_NAME, \"o-teaser__tag\")\n",
    "        tag_texts = [tag_element.text.lower() for tag_element in tag_elements]\n",
    "        \n",
    "        # Check if any of the tag texts match unwanted patterns\n",
    "        if not any(pattern.match(tag_text) for tag_text in tag_texts for pattern in unwanted_tag_patterns):\n",
    "            heading_element = teaser.find_element(By.CLASS_NAME, \"o-teaser__heading\")\n",
    "            link_element = heading_element.find_element(By.TAG_NAME, \"a\")\n",
    "            article_url = link_element.get_attribute(\"href\")\n",
    "            article_data = {\n",
    "                'url': article_url,\n",
    "                'tags': tag_texts\n",
    "            }\n",
    "            netflix_articles.append(article_data)\n",
    "\n",
    "    # Check if the \"Sorry, FT.com does not serve more than 1000 results\" message is present\n",
    "    error_message = \"Sorry, FT.com does not serve more than 1000 results\"\n",
    "    if error_message in driver.page_source:\n",
    "        break\n",
    "\n",
    "    # Click the \"Next page\" arrow to load the next page\n",
    "    next_page_arrow = driver.find_element(By.CSS_SELECTOR, \".search-pagination__next-page\")\n",
    "    next_page_arrow.click()\n",
    "\n",
    "# Print the number of collected articles\n",
    "print(len(netflix_articles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0789bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee7f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0291f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the URLs\n",
    "netflix_articles = []\n",
    "\n",
    "for x in range(1):\n",
    "    # Wait for the search results to load\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    "    )\n",
    "\n",
    "    # Find all the teaser elements\n",
    "    teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")\n",
    "\n",
    "    # Loop through the teaser elements\n",
    "    for teaser in teaser_elements:\n",
    "        heading_element = teaser.find_element(By.CLASS_NAME, \"o-teaser__heading\")\n",
    "        heading_text = heading_element.text.lower()  # Convert to lowercase for case-insensitive comparison\n",
    "        if \"netflix\" in heading_text:\n",
    "            link_element = heading_element.find_element(By.TAG_NAME, \"a\")\n",
    "            article_url = link_element.get_attribute(\"href\")\n",
    "            netflix_articles.append(article_url)\n",
    "\n",
    "    # Check if the \"Sorry, FT.com does not serve more than 1000 results\" message is present\n",
    "    error_message = \"Sorry, FT.com does not serve more than 1000 results\"\n",
    "    if error_message in driver.page_source:\n",
    "        break\n",
    "\n",
    "    # Click the \"Next page\" arrow to load the next page\n",
    "    next_page_arrow = driver.find_element(By.CSS_SELECTOR, \".search-pagination__next-page\")\n",
    "    next_page_arrow.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "18515c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ft.com/content/62efe7f4-5a87-413e-962e-6c5cb3e82b5e',\n",
       " 'https://www.ft.com/content/1156111a-4a77-40cd-9338-bd853e8956fb',\n",
       " 'https://www.ft.com/content/fda9fa7b-3a4c-4a16-b384-7867b0974074',\n",
       " 'https://www.ft.com/content/6c76b102-d012-4abd-96d7-54124f7235ef',\n",
       " 'https://www.ft.com/content/fb270603-8ca0-42da-8157-c9efcdb2e7fe',\n",
       " 'https://www.ft.com/content/4ae74277-6176-488c-995d-b92e96d3737f',\n",
       " 'https://www.ft.com/content/54188f33-5bd2-4f46-b71d-30d542b1b48d',\n",
       " 'https://www.ft.com/content/43af9830-de8f-4eb5-9302-bbd42eb915d3',\n",
       " 'https://www.ft.com/content/166a7cac-ca72-4a6e-ab0a-48bcb8cef355']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_articles[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "37eb9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(netflix_articles[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b55905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "244a500b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"c45fead74500493616d2f7963859e280\", element=\"BD428ED96A51CE30A4D443B6FA3DC253_element_20160\")>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "db9f525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# Define regular expressions to match unwanted tags\n",
    "unwanted_tag_patterns = [\n",
    "    re.compile(r'^live news updates from', re.IGNORECASE),\n",
    "    re.compile(r'^transcript', re.IGNORECASE),\n",
    "    re.compile(r'news updates from', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "# Create an empty list to store the article data\n",
    "netflix_articles = []\n",
    "\n",
    "for x in range(2):\n",
    "    # Wait for the search results to load\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    "    )\n",
    "\n",
    "    # Find all the teaser elements\n",
    "    teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")\n",
    "\n",
    "    # Loop through the teaser elements and store the article data\n",
    "    for teaser in teaser_elements:\n",
    "        tag_elements = teaser.find_elements(By.CLASS_NAME, \"o-teaser__tag\")\n",
    "        tag_texts = [tag_element.text.lower() for tag_element in tag_elements]\n",
    "        \n",
    "        # Check if any of the tag texts match unwanted patterns\n",
    "        if not any(pattern.match(tag_text) for tag_text in tag_texts for pattern in unwanted_tag_patterns):\n",
    "            link_element = teaser.find_element(By.TAG_NAME, \"a\")\n",
    "            article_url = link_element.get_attribute(\"href\")\n",
    "            article_data = {\n",
    "                'url': article_url,\n",
    "                'tags': tag_texts\n",
    "            }\n",
    "            netflix_articles.append(article_data)\n",
    "\n",
    "    # Check if the \"Sorry, FT.com does not serve more than 1000 results\" message is present\n",
    "    error_message = \"Sorry, FT.com does not serve more than 1000 results\"\n",
    "    if error_message in driver.page_source:\n",
    "        break\n",
    "\n",
    "    # Click the \"Next page\" arrow to load the next page\n",
    "    next_page_arrow = driver.find_element(By.CSS_SELECTOR, \".search-pagination__next-page\")\n",
    "    next_page_arrow.click()\n",
    "\n",
    "# Print the number of collected articles\n",
    "print(len(netflix_articles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "db23d430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ft.com/stream/2fa688f8-97f0-4596-a705-822b4a5f9d6f'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_articles[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c61fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f24ecadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the teaser elements\n",
    "teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d6a97445",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(netflix_articles[0]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "480367b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the URLs\n",
    "netflix_articles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "710d9218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netflix inc\n",
      "netflix inc\n",
      "markets\n",
      "firstft\n",
      "netflix inc\n",
      "unhedged\n",
      "netflix inc\n",
      "rana foroohar\n",
      "film\n",
      "firstft\n",
      "bloomsbury publishing plc\n",
      "ft news briefing podcast\n",
      "markets\n",
      "spotify technology sa\n",
      "equities\n",
      "netflix inc\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define regular expressions to match unwanted tags\n",
    "unwanted_tag_patterns = [\n",
    "    re.compile(r'^live news updates from', re.IGNORECASE),\n",
    "    re.compile(r'^transcript', re.IGNORECASE),\n",
    "    re.compile(r'news updates from', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "for teaser in teaser_elements:\n",
    "    # Check if the teaser contains unwanted tags\n",
    "    tag_elements = teaser.find_elements(By.CLASS_NAME, \"o-teaser__tag\")\n",
    "\n",
    "    tag_texts = [tag_element.text.lower() for tag_element in tag_elements]\n",
    "    \n",
    "    for tag_element in tag_elements:\n",
    "        tag_text = tag_element.text.lower()\n",
    "        if not any(pattern.match(tag_text) for pattern in unwanted_tag_patterns):\n",
    "            print(tag_text)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6f118a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['live news updates from april 20: spacex rocket explodes, nato chief makes first wartime ukraine visit']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeea5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the URLs\n",
    "netflix_articles = []\n",
    "\n",
    "for x in range(2):\n",
    "    # Wait for the search results to load\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    "    )\n",
    "\n",
    "    # Find all the teaser elements\n",
    "    teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")\n",
    "\n",
    "    # Loop through the teaser elements\n",
    "    for teaser in teaser_elements:\n",
    "        heading_element = teaser.find_element(By.CLASS_NAME, \"o-teaser__heading\")\n",
    "        heading_text = heading_element.text.lower()  # Convert to lowercase for case-insensitive comparison\n",
    "        if \"netflix\" in heading_text:\n",
    "            link_element = heading_element.find_element(By.TAG_NAME, \"a\")\n",
    "            article_url = link_element.get_attribute(\"href\")\n",
    "            netflix_articles.append(article_url)\n",
    "\n",
    "    # Check if the \"Sorry, FT.com does not serve more than 1000 results\" message is present\n",
    "    error_message = \"Sorry, FT.com does not serve more than 1000 results\"\n",
    "    if error_message in driver.page_source:\n",
    "        break\n",
    "\n",
    "    # Click the \"Next page\" arrow to load the next page\n",
    "    next_page_arrow = driver.find_element(By.CSS_SELECTOR, \".search-pagination__next-page\")\n",
    "    next_page_arrow.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d9d7319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of collected URLs: 15\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the URLs\n",
    "netflix_articles = []\n",
    "\n",
    "for x in range(2):\n",
    "    # Wait for the search results to load\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    "    )\n",
    "\n",
    "    # Find all the teaser elements\n",
    "    teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")\n",
    "\n",
    "    # Loop through the teaser elements\n",
    "    for teaser in teaser_elements:\n",
    "        try:\n",
    "            # Check if the teaser heading contains \"netflix\"\n",
    "            heading_element = teaser.find_element(By.CLASS_NAME, \"o-teaser__heading\")\n",
    "            heading_text = heading_element.text.lower()  # Convert to lowercase for case-insensitive comparison\n",
    "            if \"netflix\" not in heading_text:\n",
    "                continue  # Skip this element\n",
    "\n",
    "            # Check if the teaser contains unwanted tags\n",
    "            tag_elements = teaser.find_elements(By.CLASS_NAME, \"o-teaser__tag\")\n",
    "            unwanted_tags = [\"Live news updates from\", \"Transcript\"]\n",
    "            tag_text = [tag.text for tag in tag_elements]\n",
    "            if any(tag in tag_text for tag in unwanted_tags):\n",
    "                continue  # Skip this element\n",
    "\n",
    "            link_element = heading_element.find_element(By.TAG_NAME, \"a\")\n",
    "            article_url = link_element.get_attribute(\"href\")\n",
    "            netflix_articles.append(article_url)\n",
    "        except StaleElementReferenceException:\n",
    "            continue  # Skip this element if it's stale\n",
    "\n",
    "    # Check if the \"Sorry, FT.com does not serve more than 1000 results\" message is present\n",
    "    error_message = \"Sorry, FT.com does not serve more than 1000 results\"\n",
    "    if error_message in driver.page_source:\n",
    "        break\n",
    "\n",
    "    # Click the \"Next page\" arrow to load the next page\n",
    "    next_page_arrow = driver.find_element(By.CSS_SELECTOR, \".search-pagination__next-page\")\n",
    "    next_page_arrow.click()\n",
    "\n",
    "# Print the number of collected URLs\n",
    "print(\"Number of collected URLs:\", len(netflix_articles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c2a9d911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ft.com/stream/2fa688f8-97f0-4596-a705-822b4a5f9d6f',\n",
       " 'https://www.ft.com/stream/2fa688f8-97f0-4596-a705-822b4a5f9d6f',\n",
       " 'https://www.ft.com/markets',\n",
       " 'https://www.ft.com/firstft',\n",
       " 'https://www.ft.com/stream/2fa688f8-97f0-4596-a705-822b4a5f9d6f']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_articles[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea6e4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the URL using the WebDriver\n",
    "driver.get(netflix_articles[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20bcd50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of collected URLs: 1000\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the URLs\n",
    "netflix_articles = []\n",
    "\n",
    "while True:\n",
    "    # Wait for the search results to load\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    "    )\n",
    "\n",
    "    # Find all the teaser elements\n",
    "    teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")\n",
    "\n",
    "    # Loop through the teaser elements and store the URLs\n",
    "    for teaser in teaser_elements:\n",
    "        link_element = teaser.find_element(By.TAG_NAME, \"a\")\n",
    "        article_url = link_element.get_attribute(\"href\")\n",
    "        netflix_articles.append(article_url)\n",
    "\n",
    "    # Check if the \"Sorry, FT.com does not serve more than 1000 results\" message is present\n",
    "    error_message = \"Sorry, FT.com does not serve more than 1000 results\"\n",
    "    if error_message in driver.page_source:\n",
    "        break\n",
    "\n",
    "    # Click the \"Next page\" arrow to load the next page\n",
    "    next_page_arrow = driver.find_element(By.CSS_SELECTOR, \".search-pagination__next-page\")\n",
    "    next_page_arrow.click()\n",
    "# Create an empty list to store the URLs\n",
    "len(netflix_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "627dd9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ft.com/content/784012b9-4a00-460f-b466-fa17fbba8693',\n",
       " 'https://www.ft.com/content/4a9df0bd-df9d-45a7-b407-428ca8b64e7f',\n",
       " 'https://www.ft.com/stream/2fa688f8-97f0-4596-a705-822b4a5f9d6f',\n",
       " 'https://www.ft.com/stream/2fa688f8-97f0-4596-a705-822b4a5f9d6f',\n",
       " 'https://www.ft.com/markets',\n",
       " 'https://www.ft.com/transcript',\n",
       " 'https://www.ft.com/firstft',\n",
       " 'https://www.ft.com/stream/2fa688f8-97f0-4596-a705-822b4a5f9d6f',\n",
       " 'https://www.ft.com/unhedged',\n",
       " 'https://www.ft.com/stream/2fa688f8-97f0-4596-a705-822b4a5f9d6f']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the URL of the first news article\n",
    "first_url = netflix_articles[0:10]\n",
    "first_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8126fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the URL using the WebDriver\n",
    "driver.get(first_url[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a37b70a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexandra White\n",
      "Live news updates from July 21: Tech firms make AI safety pledge, Japan inflation hits 3.3%\n",
      "Alternative Date: 2023-07-21\n",
      "Alternative Time: 21:03:18\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m# Extract and print the full article text\u001b[39;00m\n\u001b[1;32m     54\u001b[0m article_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 55\u001b[0m \u001b[39mfor\u001b[39;00m paragraph \u001b[39min\u001b[39;00m article_content_element\u001b[39m.\u001b[39;49mfind_all(\u001b[39m\"\u001b[39m\u001b[39mp\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     56\u001b[0m     article_text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m paragraph\u001b[39m.\u001b[39mget_text() \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[39mprint\u001b[39m(article_text)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Open the URL using the WebDriver\n",
    "driver.get(first_url)\n",
    "\n",
    "# Get the page source (HTML content) after it's fully loaded\n",
    "page_source = driver.page_source\n",
    "\n",
    "\n",
    "# Parse the page source using BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "\n",
    "# Find the author's link\n",
    "author_link = soup.find(\"a\", class_=\"n-content-tag--author\")\n",
    "\n",
    "# Extract and print the author's name\n",
    "author_name = author_link.text\n",
    "print(author_name)\n",
    "\n",
    "# Find the heading element\n",
    "heading_element = soup.find(\"h1\", class_=\"o-topper__headline\")\n",
    "\n",
    "# Find the inner span element within the heading element\n",
    "span_element = heading_element.find(\"span\", class_=\"article-classifier__gap\")\n",
    "\n",
    "# Extract and print the heading text\n",
    "heading = span_element.text\n",
    "print(heading)\n",
    "\n",
    "# Find the timestamp element using the first method\n",
    "timestamp_element = soup.find(\"time\", class_=\"article-info__timestamp\")\n",
    "\n",
    "if timestamp_element:\n",
    "    # Extract and print the timestamp\n",
    "    timestamp = timestamp_element['datetime']\n",
    "    date, time = timestamp.split('T')\n",
    "    print(\"Date:\", date)\n",
    "    print(\"Time:\", time[:-5])  # Remove the milliseconds and 'Z'\n",
    "else:\n",
    "    # Try the second method to extract timestamp\n",
    "    alt_timestamp_element = soup.find(\"time\", class_=\"x-live-blog-post__timestamp\")\n",
    "    if alt_timestamp_element:\n",
    "        alt_timestamp = alt_timestamp_element['datetime']\n",
    "        alt_date, alt_time = alt_timestamp.split('T')\n",
    "        print(\"Alternative Date:\", alt_date)\n",
    "        print(\"Alternative Time:\", alt_time[:-5])\n",
    "    else:\n",
    "        print(\"Timestamp not found\")\n",
    "\n",
    "\n",
    "# Find the article content element\n",
    "article_content_element = soup.find(\"div\", class_=\"article__content-body\")\n",
    "\n",
    "# Extract and print the full article text\n",
    "article_text = \"\"\n",
    "for paragraph in article_content_element.find_all(\"p\"):\n",
    "    article_text += paragraph.get_text() + \"\\n\"\n",
    "\n",
    "print(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2d527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a0b67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a3a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea037efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6231f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the search button element\n",
    "search_button = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//a[contains(@class, 'o-header__top-icon-link--search')]\"))\n",
    ")\n",
    "\n",
    "# Scroll to the search button element\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", search_button)\n",
    "\n",
    "\n",
    "# Simulate a click using JavaScript\n",
    "driver.execute_script(\"arguments[0].click();\", search_button)\n",
    "# Find the search input element\n",
    "search_input = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//input[@id='o-header-search-term-primary']\"))\n",
    ")\n",
    "\n",
    "# Clear any existing text and type \n",
    "search_input.clear()\n",
    "search_input.send_keys(\"netflix financial result\")\n",
    "\n",
    "# Find the search button element\n",
    "search_button = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//button[@class='o-header__search-submit']\"))\n",
    ")\n",
    "\n",
    "# Click the search button\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "712db3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923\n"
     ]
    }
   ],
   "source": [
    "# Define regular expressions to match unwanted tags\n",
    "unwanted_tag_patterns = [\n",
    "    re.compile(r'^live news updates from', re.IGNORECASE),\n",
    "    re.compile(r'^transcript', re.IGNORECASE),\n",
    "    re.compile(r'news updates from', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "# Create an empty list to store the article URLs\n",
    "netflix_article_urls = []\n",
    "\n",
    "while True:\n",
    "    # Wait for the search results to load\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    "    )\n",
    "\n",
    "    # Find all the teaser elements\n",
    "    teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")\n",
    "\n",
    "    # Loop through the teaser elements and store the article URLs\n",
    "    for teaser in teaser_elements:\n",
    "        tag_elements = teaser.find_elements(By.CLASS_NAME, \"o-teaser__tag\")\n",
    "        tag_texts = [tag_element.text.lower() for tag_element in tag_elements]\n",
    "        \n",
    "        # Check if any of the tag texts match unwanted patterns\n",
    "        if not any(pattern.match(tag_text) for tag_text in tag_texts for pattern in unwanted_tag_patterns):\n",
    "            heading_element = teaser.find_element(By.CLASS_NAME, \"o-teaser__heading\")\n",
    "            link_element = heading_element.find_element(By.TAG_NAME, \"a\")\n",
    "            article_url = link_element.get_attribute(\"href\")\n",
    "            netflix_article_urls.append(article_url)\n",
    "\n",
    "    # Check if the \"Sorry, FT.com does not serve more than 1000 results\" message is present\n",
    "    error_message = \"Sorry, FT.com does not serve more than 1000 results\"\n",
    "    if error_message in driver.page_source:\n",
    "        break\n",
    "\n",
    "    # Click the \"Next page\" arrow to load the next page\n",
    "    next_page_arrow = driver.find_element(By.CSS_SELECTOR, \".search-pagination__next-page\")\n",
    "    next_page_arrow.click()\n",
    "\n",
    "# Print the number of collected article URLs\n",
    "print(len(netflix_article_urls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8136b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb743f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(netflix_article_urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4584e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netflix: password sharing cutback provides shortlived gain \n",
      "Date: 2023-07-20\n",
      "Time: 10:36:06\n",
      "Offering the same service at higher prices suggests a paucity of ideas. Netflix is eliminating free password sharing in a bid to force freeloading viewers to pay up. The result was a 5.9mn bump in subscriber numbers in this year’s second quarter that was hailed as a show of strength by some analysts. But this is only a temporary fix.\n",
      "Like ride-sharing company Uber, Netflix priced its streaming service at low rates to attract the biggest audience possible. Like Uber, it was then bombarded by rivals willing to spend large sums to compete. Six years ago, Netflix claimed that its only real competition was sleep. Now it includes comparisons to streaming competitors in its shareholder letter. \n",
      "As its shareholders grow weary of subsidising online services, prices are rising. NBCUniversal’s Peacock just lifted its cheapest monthly rate by $1 and Disney+’s US revenue per subscriber has picked up by 20 per cent in the past year.\n",
      "This means Netflix’s increases do not stand out. It is still the sector leader with nearly 239mn subscribers and expects another increase this quarter. But Netflix must spend more on marketing to draw in those subscribers. \n",
      "Lower costs are temporary too. In a repeat of the shutdowns that occurred during Covid-19 lockdowns, the Hollywood writers’ strike has stopped production of films and TV shows. That means Netflix will spend less on content. Free cash flow is expected to be at least $5bn this year, up from $1.6bn in 2022. Long-term debt has come down as well to $14.1bn from $14.9bn two years ago. One can sense that the focus is on level-headed financial decisions just by the near total lack of chatter about video games — an expensive endeavour that Netflix is also involved in. \n",
      "But when all of the users who were sharing passwords pay up or leave, Netflix will have to find new sources of revenue growth. Advertising subscriptions are not yet large enough for Netflix to choose to put a number on them. It is also a crowded field. Everyone, from YouTube to Uber, now tries to attract ad dollars. \n",
      "If Netflix wants to keep its focus on tweaking payments it could remove monthly subscriptions altogether and reduce churn by offering only annual or 18-month plans. Month-by-month payments were once a way to distinguish streaming from cable TV. That differentiation is no longer necessary. \n",
      "Listen to Lex deputy editor Elaine Moore talk to creators, companies and critics about the next era of social media in the FT’s new Tech Tonic podcast series.\n",
      "Highlight\n",
      "Remove highlight\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the page source (HTML content) after it's fully loaded\n",
    "page_source = driver.page_source\n",
    "\n",
    "\n",
    "# Parse the page source using BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "\n",
    "# Find the author's link\n",
    "#author_link = soup.find(\"a\", class_=\"n-content-tag--author\")\n",
    "\n",
    "# Extract and print the author's name\n",
    "#author_name = author_link.text\n",
    "#print(author_name)\n",
    "\n",
    "#author info may not be there in some cases\n",
    "\n",
    "# Find the heading element\n",
    "heading_element = soup.find(\"h1\", class_=\"o-topper__headline\")\n",
    "\n",
    "# Find the inner span element within the heading element\n",
    "span_element = heading_element.find(\"span\", class_=\"article-classifier__gap\")\n",
    "\n",
    "# Extract and print the heading text\n",
    "heading = span_element.text\n",
    "print(heading)\n",
    "\n",
    "# Find the timestamp element\n",
    "timestamp_element = soup.find(\"time\", class_=\"article-info__timestamp\")\n",
    "\n",
    "# Extract and print the timestamp\n",
    "timestamp = timestamp_element['datetime']\n",
    "date, time = timestamp.split('T')\n",
    "print(\"Date:\", date)\n",
    "print(\"Time:\", time[:-5])  # Remove the milliseconds and 'Z'\n",
    "\n",
    "# Find the article content element\n",
    "article_content_element = soup.find(\"div\", class_=\"article__content-body\")\n",
    "\n",
    "# Extract and print the full article text\n",
    "article_text = \"\"\n",
    "for paragraph in article_content_element.find_all(\"p\"):\n",
    "    article_text += paragraph.get_text() + \"\\n\"\n",
    "\n",
    "print(article_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cace2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the scraped data\n",
    "scraped_data = []\n",
    "error_log = []\n",
    "\n",
    "\n",
    "\n",
    "# Loop through the URLs\n",
    "for url in netflix_article_urls:\n",
    "    try:\n",
    "        # Open the URL using ChromeDriver\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Get the page source after waiting for a bit to ensure it's fully loaded\n",
    "        driver.implicitly_wait(5)\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        # Parse the page source using Beautiful Soup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        # Find the author's link\n",
    "        try:\n",
    "            author_link = soup.find(\"a\", class_=\"n-content-tag--author\")\n",
    "            author_name = author_link.text if author_link else \"Unknown Author\"\n",
    "        except Exception as author_err:\n",
    "            author_name = \"Error extracting author\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Author\", \"error\": str(author_err)})\n",
    "        \n",
    "        # Find the heading element\n",
    "        try:\n",
    "            heading_element = soup.find(\"h1\", class_=\"o-topper__headline\")\n",
    "            heading = heading_element.text if heading_element else \"Unknown Heading\"\n",
    "        except Exception as heading_err:\n",
    "            heading = \"Error extracting heading\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Heading\", \"error\": str(heading_err)})\n",
    "        \n",
    "        # Find the timestamp element\n",
    "        try:\n",
    "            timestamp_element = soup.find(\"time\", class_=\"article-info__timestamp\")\n",
    "            timestamp = timestamp_element['datetime'] if timestamp_element else \"Unknown Timestamp\"\n",
    "            date, time = timestamp.split('T')\n",
    "        except Exception as timestamp_err:\n",
    "            date = \"Unknown Date\"\n",
    "            time = \"Unknown Time\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Timestamp\", \"error\": str(timestamp_err)})\n",
    "        \n",
    "        # Find the article content element\n",
    "        try:\n",
    "            article_content_element = soup.find(\"div\", class_=\"article__content-body\")\n",
    "            \n",
    "            # Extract the full article text\n",
    "            article_text = \"\"\n",
    "            for paragraph in article_content_element.find_all(\"p\"):\n",
    "                article_text += paragraph.get_text() + \"\\n\"\n",
    "        except Exception as article_err:\n",
    "            article_text = \"Error extracting article text\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Article\", \"error\": str(article_err)})\n",
    "        \n",
    "        # Store the scraped data in a dictionary\n",
    "        scraped_data.append({\n",
    "            \"url\": url,\n",
    "            \"author\": author_name,\n",
    "            \"heading\": heading,\n",
    "            \"date\": date,\n",
    "            \"time\": time[:-5],\n",
    "            \"article_text\": article_text\n",
    "        })\n",
    "    \n",
    "    except Exception as page_err:\n",
    "        error_log.append({\"url\": url, \"field\": \"Page\", \"error\": str(page_err)})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a87f30b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "923"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "906f0906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8153b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1=pd.DataFrame(scraped_data)\n",
    "\n",
    "# Remove rows with problematic or incomplete data\n",
    "df_cleaned_1 = df_new_1[\n",
    "    (df_new_1['author'] != 'Unknown Author') &\n",
    "    (df_new_1['heading'] != 'Unknown Heading') &\n",
    "    (df_new_1['date'] != 'Unknown') &\n",
    "    (df_new_1['time'] != 'ime')\n",
    "]\n",
    "\n",
    "df_cleaned_1 = df_cleaned_1.copy()\n",
    "df_cleaned_1['date'] = pd.to_datetime(df_cleaned_1['date'])\n",
    "\n",
    "\n",
    "# Sort the DataFrame by the 'date' column in descending order\n",
    "df_sorted_1 = df_cleaned_1.sort_values(by='date', ascending=False)\n",
    "\n",
    "# Print the cleaned and sorted DataFrame\n",
    "\n",
    "df_sorted_1.to_csv('ft_articles_fin_result_search.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4981e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>https://www.ft.com/content/16ac973e-5fb4-40a8-...</td>\n",
       "      <td>Ian Smith</td>\n",
       "      <td>European insurers say US backlash has damaged ...</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>13:00:11</td>\n",
       "      <td>The heads of Europe’s largest insurers have wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>https://www.ft.com/content/9f0308fd-027e-4005-...</td>\n",
       "      <td>Laura Onita</td>\n",
       "      <td>How high street stalwart Wilko came unstuck</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>03:00:46</td>\n",
       "      <td>Some shelves have lain empty for months as Wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>https://www.ft.com/content/997808ab-8226-45b2-...</td>\n",
       "      <td>Mitchell Labiak</td>\n",
       "      <td>Directors’ Deals: Segro chair increases his stake</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>17:00:51</td>\n",
       "      <td>Segro’s chair has upped his stake in the FTSE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>https://www.ft.com/content/e7ff9e85-7472-40d8-...</td>\n",
       "      <td>Eric Platt</td>\n",
       "      <td>Retail investors help lift Warren Buffett’s Be...</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>17:00:51</td>\n",
       "      <td>Warren Buffett’s Berkshire Hathaway surged to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>https://www.ft.com/content/51548b4e-4046-495a-...</td>\n",
       "      <td>Moira O’Neill</td>\n",
       "      <td>How to help children pay for university</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>04:00:46</td>\n",
       "      <td>The ever-growing burden of financing universit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url           author  \\\n",
       "270  https://www.ft.com/content/16ac973e-5fb4-40a8-...        Ian Smith   \n",
       "139  https://www.ft.com/content/9f0308fd-027e-4005-...      Laura Onita   \n",
       "99   https://www.ft.com/content/997808ab-8226-45b2-...  Mitchell Labiak   \n",
       "212  https://www.ft.com/content/e7ff9e85-7472-40d8-...       Eric Platt   \n",
       "623  https://www.ft.com/content/51548b4e-4046-495a-...    Moira O’Neill   \n",
       "\n",
       "                                               heading       date      time  \\\n",
       "270  European insurers say US backlash has damaged ... 2023-08-12  13:00:11   \n",
       "139       How high street stalwart Wilko came unstuck  2023-08-11  03:00:46   \n",
       "99   Directors’ Deals: Segro chair increases his stake 2023-08-11  17:00:51   \n",
       "212  Retail investors help lift Warren Buffett’s Be... 2023-08-11  17:00:51   \n",
       "623            How to help children pay for university 2023-08-11  04:00:46   \n",
       "\n",
       "                                          article_text  \n",
       "270  The heads of Europe’s largest insurers have wa...  \n",
       "139  Some shelves have lain empty for months as Wil...  \n",
       "99   Segro’s chair has upped his stake in the FTSE ...  \n",
       "212  Warren Buffett’s Berkshire Hathaway surged to ...  \n",
       "623  The ever-growing burden of financing universit...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d7e8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the search button element\n",
    "search_button = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//a[contains(@class, 'o-header__top-icon-link--search')]\"))\n",
    ")\n",
    "\n",
    "# Scroll to the search button element\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", search_button)\n",
    "\n",
    "\n",
    "# Simulate a click using JavaScript\n",
    "driver.execute_script(\"arguments[0].click();\", search_button)\n",
    "# Find the search input element\n",
    "search_input = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//input[@id='o-header-search-term-primary']\"))\n",
    ")\n",
    "\n",
    "# Clear any existing text and type \n",
    "search_input.clear()\n",
    "search_input.send_keys(\"netflix\")\n",
    "\n",
    "# Find the search button element\n",
    "search_button = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//button[@class='o-header__search-submit']\"))\n",
    ")\n",
    "\n",
    "# Click the search button\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f3a76c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895\n"
     ]
    }
   ],
   "source": [
    "# Define regular expressions to match unwanted tags\n",
    "unwanted_tag_patterns = [\n",
    "    re.compile(r'^live news updates from', re.IGNORECASE),\n",
    "    re.compile(r'^transcript', re.IGNORECASE),\n",
    "    re.compile(r'news updates from', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "# Create an empty list to store the article URLs\n",
    "netflix_article_urls = []\n",
    "\n",
    "while True:\n",
    "    # Wait for the search results to load\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"o-teaser__content\"))\n",
    "    )\n",
    "\n",
    "    # Find all the teaser elements\n",
    "    teaser_elements = driver.find_elements(By.CLASS_NAME, \"o-teaser__content\")\n",
    "\n",
    "    # Loop through the teaser elements and store the article URLs\n",
    "    for teaser in teaser_elements:\n",
    "        tag_elements = teaser.find_elements(By.CLASS_NAME, \"o-teaser__tag\")\n",
    "        tag_texts = [tag_element.text.lower() for tag_element in tag_elements]\n",
    "        \n",
    "        # Check if any of the tag texts match unwanted patterns\n",
    "        if not any(pattern.match(tag_text) for tag_text in tag_texts for pattern in unwanted_tag_patterns):\n",
    "            heading_element = teaser.find_element(By.CLASS_NAME, \"o-teaser__heading\")\n",
    "            link_element = heading_element.find_element(By.TAG_NAME, \"a\")\n",
    "            article_url = link_element.get_attribute(\"href\")\n",
    "            netflix_article_urls.append(article_url)\n",
    "\n",
    "    # Check if the \"Sorry, FT.com does not serve more than 1000 results\" message is present\n",
    "    error_message = \"Sorry, FT.com does not serve more than 1000 results\"\n",
    "    if error_message in driver.page_source:\n",
    "        break\n",
    "\n",
    "    # Click the \"Next page\" arrow to load the next page\n",
    "    next_page_arrow = driver.find_element(By.CSS_SELECTOR, \".search-pagination__next-page\")\n",
    "    next_page_arrow.click()\n",
    "\n",
    "# Print the number of collected article URLs\n",
    "print(len(netflix_article_urls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fb97ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(netflix_article_urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4651997f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daniel Thomas\n",
      "Netflix to revamp advertising strategy to lure brands and boost revenues\n",
      "Date: 2023-07-03\n",
      "Time: 04:00:10\n",
      "Netflix will develop increasingly targeted and tailor-made advertising formats to win over marketing bosses as it seeks to boost revenues in its recently launched advertising supported service.\n",
      "The US streaming service held talks with global advertising executives about new plans at this year’s Cannes Lions festival in the south of France after launching the ad-supported service last year. \n",
      "Advertising executives said innovations could include “episodic” campaigns that would see a series of different but related sequential ads to consumers, which would avoid the common complaint of consumers of being shown the same ad multiple times when watching a series. These could be shown during related shows — for example, light entertainment — but not others.\n",
      "Netflix was a prominent presence at the vast festival of advertising in its first year at the event, hosting a party in a branded hotel on the seafront and an event with ex-footballer David Beckham. \n",
      "Netflix co-chief executive Greg Peters and Jeremi Gorman, president of worldwide advertising at Netflix, spent the week in France courting advertising bosses and brands, according to multiple advertising executives.\n",
      "They said that their counterparts at Netflix outlined how the US media giant would introduce sophisticated ways for brands to advertise as part of a long-term strategy to redefine how streamers can use their platforms for commercial purposes. This includes allowing brands to more directly target advertising to consumers in ways not possible on linear TV channels.\n",
      "One Hollywood marketing executive said that the partnership to use Microsoft’s technology was also likely to come to an end next year, which would allow Netflix greater ability to innovate. \n",
      "“They’re building [their own technology] in the background. Once they have their own they’ll do free standing. Microsoft is the interim ad server, but that’ll change when they build their own,” he said. \n",
      "“The plan for Netflix was just to get to market quickly last year. This is not the final way they’re going to do it. They are going to be very creative. There’s going to be a better, a different experience.”\n",
      "One advertising boss said Netflix would be able to use its data on customers to create more bespoke marketing, albeit in ways still safeguarding customer data protections. \n",
      "“They’ll know what you’ve seen,” he said. “So the old days of making episodic work may be back because before you could never guarantee what people have seen already. Now you can write 15 episodes of an advert and guarantee that the viewer will see them in the right order. So that’s really interesting.”\n",
      "Another advertising chief said Netflix now made more money per user on its advertising plans than in the standard tier. He said brands had been positive on the idea of using Netflix to market their products, although he added that the size of the audience was still small.\n",
      "“Streaming services thought it would devalue their offer. But actually, it’s massively expanded the reach. Brands are extremely keen to be associated with the Netflix content and now they’re starting to think about much more innovation around the format, much more strategic partnerships.”\n",
      "Another advertising executive said: “What level of targeting that they start to apply could get really, really interesting. We were keen for some of our brands to use it so that we could see what was coming [but] we can’t correlate exposure to Netflix to sales — it’s just too small. But you can get learning about who saw your ads.”\n",
      "Netflix is also seeking to build out its gaming business to include advertising, noted another ad executive. Others added that they expected Apple to follow Netflix and introduce advertising alongside its shows and products. Netflix and Microsoft declined to comment.\n",
      "Highlight\n",
      "Remove highlight\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the page source (HTML content) after it's fully loaded\n",
    "page_source = driver.page_source\n",
    "\n",
    "\n",
    "# Parse the page source using BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "\n",
    "# Find the author's link\n",
    "author_link = soup.find(\"a\", class_=\"n-content-tag--author\")\n",
    "\n",
    "# Extract and print the author's name\n",
    "author_name = author_link.text\n",
    "print(author_name)\n",
    "\n",
    "#author info may not be there in some cases\n",
    "\n",
    "# Find the heading element\n",
    "heading_element = soup.find(\"h1\", class_=\"o-topper__headline\")\n",
    "\n",
    "# Find the inner span element within the heading element\n",
    "span_element = heading_element.find(\"span\", class_=\"article-classifier__gap\")\n",
    "\n",
    "# Extract and print the heading text\n",
    "heading = span_element.text\n",
    "print(heading)\n",
    "\n",
    "# Find the timestamp element\n",
    "timestamp_element = soup.find(\"time\", class_=\"article-info__timestamp\")\n",
    "\n",
    "# Extract and print the timestamp\n",
    "timestamp = timestamp_element['datetime']\n",
    "date, time = timestamp.split('T')\n",
    "print(\"Date:\", date)\n",
    "print(\"Time:\", time[:-5])  # Remove the milliseconds and 'Z'\n",
    "\n",
    "# Find the article content element\n",
    "article_content_element = soup.find(\"div\", class_=\"article__content-body\")\n",
    "\n",
    "# Extract and print the full article text\n",
    "article_text = \"\"\n",
    "for paragraph in article_content_element.find_all(\"p\"):\n",
    "    article_text += paragraph.get_text() + \"\\n\"\n",
    "\n",
    "print(article_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19bcfefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the scraped data\n",
    "scraped_data = []\n",
    "error_log = []\n",
    "\n",
    "\n",
    "\n",
    "# Loop through the URLs\n",
    "for url in netflix_article_urls:\n",
    "    try:\n",
    "        # Open the URL using ChromeDriver\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Get the page source after waiting for a bit to ensure it's fully loaded\n",
    "        driver.implicitly_wait(5)\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        # Parse the page source using Beautiful Soup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        # Find the author's link\n",
    "        try:\n",
    "            author_link = soup.find(\"a\", class_=\"n-content-tag--author\")\n",
    "            author_name = author_link.text if author_link else \"Unknown Author\"\n",
    "        except Exception as author_err:\n",
    "            author_name = \"Error extracting author\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Author\", \"error\": str(author_err)})\n",
    "        \n",
    "        # Find the heading element\n",
    "        try:\n",
    "            heading_element = soup.find(\"h1\", class_=\"o-topper__headline\")\n",
    "            heading = heading_element.text if heading_element else \"Unknown Heading\"\n",
    "        except Exception as heading_err:\n",
    "            heading = \"Error extracting heading\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Heading\", \"error\": str(heading_err)})\n",
    "        \n",
    "        # Find the timestamp element\n",
    "        try:\n",
    "            timestamp_element = soup.find(\"time\", class_=\"article-info__timestamp\")\n",
    "            timestamp = timestamp_element['datetime'] if timestamp_element else \"Unknown Timestamp\"\n",
    "            date, time = timestamp.split('T')\n",
    "        except Exception as timestamp_err:\n",
    "            date = \"Unknown Date\"\n",
    "            time = \"Unknown Time\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Timestamp\", \"error\": str(timestamp_err)})\n",
    "        \n",
    "        # Find the article content element\n",
    "        try:\n",
    "            article_content_element = soup.find(\"div\", class_=\"article__content-body\")\n",
    "            \n",
    "            # Extract the full article text\n",
    "            article_text = \"\"\n",
    "            for paragraph in article_content_element.find_all(\"p\"):\n",
    "                article_text += paragraph.get_text() + \"\\n\"\n",
    "        except Exception as article_err:\n",
    "            article_text = \"Error extracting article text\"\n",
    "            error_log.append({\"url\": url, \"field\": \"Article\", \"error\": str(article_err)})\n",
    "        \n",
    "        # Store the scraped data in a dictionary\n",
    "        scraped_data.append({\n",
    "            \"url\": url,\n",
    "            \"author\": author_name,\n",
    "            \"heading\": heading,\n",
    "            \"date\": date,\n",
    "            \"time\": time[:-5],\n",
    "            \"article_text\": article_text\n",
    "        })\n",
    "    \n",
    "    except Exception as page_err:\n",
    "        error_log.append({\"url\": url, \"field\": \"Page\", \"error\": str(page_err)})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5db6da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1=pd.DataFrame(scraped_data)\n",
    "\n",
    "# Remove rows with problematic or incomplete data\n",
    "df_cleaned_1 = df_new_1[\n",
    "    (df_new_1['author'] != 'Unknown Author') &\n",
    "    (df_new_1['heading'] != 'Unknown Heading') &\n",
    "    (df_new_1['date'] != 'Unknown') &\n",
    "    (df_new_1['time'] != 'ime')\n",
    "]\n",
    "\n",
    "df_cleaned_1 = df_cleaned_1.copy()\n",
    "df_cleaned_1['date'] = pd.to_datetime(df_cleaned_1['date'])\n",
    "\n",
    "\n",
    "# Sort the DataFrame by the 'date' column in descending order\n",
    "df_sorted_1 = df_cleaned_1.sort_values(by='date', ascending=False)\n",
    "\n",
    "# Print the cleaned and sorted DataFrame\n",
    "\n",
    "df_sorted_1.to_csv('ft_articles_netflix_result_search.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f020142f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>https://www.ft.com/content/79ce8a38-002a-43a7-...</td>\n",
       "      <td>Anna Nicolaou</td>\n",
       "      <td>SEC sues three former Netflix engineers over i...</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>21:15:02</td>\n",
       "      <td>The Securities and Exchange Commission has sue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>https://www.ft.com/content/dd3ec41d-2e0f-4f36-...</td>\n",
       "      <td>Suzi Feay</td>\n",
       "      <td>Sandra Oh is endlessly endearing and empatheti...</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>14:02:12</td>\n",
       "      <td>When Dr Ji-Yoon Kim starts her first day as ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>https://www.ft.com/content/7d84dfa0-c88a-4380-...</td>\n",
       "      <td>Tim Bradshaw</td>\n",
       "      <td>Why Netflix is moving into gaming</td>\n",
       "      <td>2021-07-24</td>\n",
       "      <td>04:00:54</td>\n",
       "      <td>For years, Netflix has watched as the world’s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>https://www.ft.com/content/d0c787dd-3774-45f2-...</td>\n",
       "      <td>Anna Nicolaou</td>\n",
       "      <td>HBO Max gains US subscribers as Netflix slips</td>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>11:58:14</td>\n",
       "      <td>HBO Max signed up 2.4m new subscribers in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>https://www.ft.com/content/f510653f-95d7-4d2e-...</td>\n",
       "      <td>Tim Bradshaw</td>\n",
       "      <td>Netflix moves into gaming with executive hire</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>11:49:37</td>\n",
       "      <td>Netflix is accelerating its move into video ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url         author  \\\n",
       "803  https://www.ft.com/content/79ce8a38-002a-43a7-...  Anna Nicolaou   \n",
       "892  https://www.ft.com/content/dd3ec41d-2e0f-4f36-...      Suzi Feay   \n",
       "827  https://www.ft.com/content/7d84dfa0-c88a-4380-...   Tim Bradshaw   \n",
       "837  https://www.ft.com/content/d0c787dd-3774-45f2-...  Anna Nicolaou   \n",
       "831  https://www.ft.com/content/f510653f-95d7-4d2e-...   Tim Bradshaw   \n",
       "\n",
       "                                               heading       date      time  \\\n",
       "803  SEC sues three former Netflix engineers over i... 2021-08-18  21:15:02   \n",
       "892  Sandra Oh is endlessly endearing and empatheti... 2021-08-13  14:02:12   \n",
       "827                  Why Netflix is moving into gaming 2021-07-24  04:00:54   \n",
       "837      HBO Max gains US subscribers as Netflix slips 2021-07-22  11:58:14   \n",
       "831      Netflix moves into gaming with executive hire 2021-07-15  11:49:37   \n",
       "\n",
       "                                          article_text  \n",
       "803  The Securities and Exchange Commission has sue...  \n",
       "892  When Dr Ji-Yoon Kim starts her first day as ch...  \n",
       "827  For years, Netflix has watched as the world’s ...  \n",
       "837  HBO Max signed up 2.4m new subscribers in the ...  \n",
       "831  Netflix is accelerating its move into video ga...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "952a7c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=pd.read_csv(\"ft_articles_05.csv\")\n",
    "df_2=pd.read_csv(\"ft_articles_2023_07_19_to_2017_10_05.csv\")\n",
    "df_3=pd.read_csv(\"ft_articles_fin_result_search.csv\")\n",
    "df_4=pd.read_csv(\"ft_articles_netflix_result_search.csv\")\n",
    "df_5_yahoo=pd.read_csv(\"netflix_news_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d84d3c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ft.com/content/094c6b7e-f3f0-4a2b-...</td>\n",
       "      <td>Leonard Barden</td>\n",
       "      <td>Chess: Rishi Sunak to announce £500,000 govern...</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>14:48:29</td>\n",
       "      <td>Rishi Sunak will shortly announce £500,000 gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ft.com/content/ada5e725-1138-43e8-...</td>\n",
       "      <td>Darren Dodd</td>\n",
       "      <td>A slowdown in US jobs growth suggests success ...</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>17:15:27</td>\n",
       "      <td>This article is an on-site version of our Disr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ft.com/content/7c4ae9e7-304e-4394-...</td>\n",
       "      <td>Gordon Smith</td>\n",
       "      <td>FirstFT: Goldman exodus as top executives head...</td>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>10:32:52</td>\n",
       "      <td>The departure of three partners from Goldman S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ft.com/content/17d63b45-6005-499d-...</td>\n",
       "      <td>Patrick McGee</td>\n",
       "      <td>Apple profits rise as services arm surpasses 1...</td>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>22:57:03</td>\n",
       "      <td>Apple proved resilient in its latest quarter a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ft.com/content/425d1a9c-b8ff-4a17-...</td>\n",
       "      <td>Stephen Bush</td>\n",
       "      <td>What Barbenheimer teaches us about the pointle...</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>04:00:13</td>\n",
       "      <td>The phrase “know your enemy” is generally syno...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url          author  \\\n",
       "0  https://www.ft.com/content/094c6b7e-f3f0-4a2b-...  Leonard Barden   \n",
       "1  https://www.ft.com/content/ada5e725-1138-43e8-...     Darren Dodd   \n",
       "2  https://www.ft.com/content/7c4ae9e7-304e-4394-...    Gordon Smith   \n",
       "3  https://www.ft.com/content/17d63b45-6005-499d-...   Patrick McGee   \n",
       "4  https://www.ft.com/content/425d1a9c-b8ff-4a17-...    Stephen Bush   \n",
       "\n",
       "                                             heading        date      time  \\\n",
       "0  Chess: Rishi Sunak to announce £500,000 govern...  2023-08-08  14:48:29   \n",
       "1  A slowdown in US jobs growth suggests success ...  2023-08-04  17:15:27   \n",
       "2  FirstFT: Goldman exodus as top executives head...  2023-08-03  10:32:52   \n",
       "3  Apple profits rise as services arm surpasses 1...  2023-08-03  22:57:03   \n",
       "4  What Barbenheimer teaches us about the pointle...  2023-08-01  04:00:13   \n",
       "\n",
       "                                        article_text  \n",
       "0  Rishi Sunak will shortly announce £500,000 gov...  \n",
       "1  This article is an on-site version of our Disr...  \n",
       "2  The departure of three partners from Goldman S...  \n",
       "3  Apple proved resilient in its latest quarter a...  \n",
       "4  The phrase “know your enemy” is generally syno...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0791052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ft.com/content/fda9fa7b-3a4c-4a16-...</td>\n",
       "      <td>Anna Nicolaou</td>\n",
       "      <td>Netflix’s password-sharing crackdown pays off ...</td>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>21:37:20</td>\n",
       "      <td>A crackdown on password sharing helped Netflix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ft.com/content/1cc91834-ef81-4a5d-...</td>\n",
       "      <td>Akito Tanaka</td>\n",
       "      <td>US tech can’t quit China and Netflix dives int...</td>\n",
       "      <td>2023-07-13</td>\n",
       "      <td>07:26:38</td>\n",
       "      <td>Hello everyone, this is Akito from Singapore.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ft.com/content/dc79eecf-ed3c-486a-...</td>\n",
       "      <td>Daniel Thomas</td>\n",
       "      <td>Netflix to revamp advertising strategy to lure...</td>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>04:00:10</td>\n",
       "      <td>Netflix will develop increasingly targeted and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ft.com/content/a85f2d38-1889-4108-...</td>\n",
       "      <td>Christopher Grimes</td>\n",
       "      <td>Netflix is taking a necessary risk in tackling...</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>04:00:49</td>\n",
       "      <td>When Netflix co-founder Reed Hastings declared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ft.com/content/13f719af-b406-4c53-...</td>\n",
       "      <td>Daniel Thomas</td>\n",
       "      <td>Netflix alerts telecoms groups over looming ac...</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>10:00:32</td>\n",
       "      <td>Netflix has held talks with UK telecoms groups...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url              author  \\\n",
       "0  https://www.ft.com/content/fda9fa7b-3a4c-4a16-...       Anna Nicolaou   \n",
       "1  https://www.ft.com/content/1cc91834-ef81-4a5d-...        Akito Tanaka   \n",
       "2  https://www.ft.com/content/dc79eecf-ed3c-486a-...       Daniel Thomas   \n",
       "3  https://www.ft.com/content/a85f2d38-1889-4108-...  Christopher Grimes   \n",
       "4  https://www.ft.com/content/13f719af-b406-4c53-...       Daniel Thomas   \n",
       "\n",
       "                                             heading        date      time  \\\n",
       "0  Netflix’s password-sharing crackdown pays off ...  2023-07-19  21:37:20   \n",
       "1  US tech can’t quit China and Netflix dives int...  2023-07-13  07:26:38   \n",
       "2  Netflix to revamp advertising strategy to lure...  2023-07-03  04:00:10   \n",
       "3  Netflix is taking a necessary risk in tackling...  2023-05-26  04:00:49   \n",
       "4  Netflix alerts telecoms groups over looming ac...  2023-05-16  10:00:32   \n",
       "\n",
       "                                        article_text  \n",
       "0  A crackdown on password sharing helped Netflix...  \n",
       "1  Hello everyone, this is Akito from Singapore.\\...  \n",
       "2  Netflix will develop increasingly targeted and...  \n",
       "3  When Netflix co-founder Reed Hastings declared...  \n",
       "4  Netflix has held talks with UK telecoms groups...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca68bb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ft.com/content/16ac973e-5fb4-40a8-...</td>\n",
       "      <td>Ian Smith</td>\n",
       "      <td>European insurers say US backlash has damaged ...</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>13:00:11</td>\n",
       "      <td>The heads of Europe’s largest insurers have wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ft.com/content/9f0308fd-027e-4005-...</td>\n",
       "      <td>Laura Onita</td>\n",
       "      <td>How high street stalwart Wilko came unstuck</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>03:00:46</td>\n",
       "      <td>Some shelves have lain empty for months as Wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ft.com/content/997808ab-8226-45b2-...</td>\n",
       "      <td>Mitchell Labiak</td>\n",
       "      <td>Directors’ Deals: Segro chair increases his stake</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>17:00:51</td>\n",
       "      <td>Segro’s chair has upped his stake in the FTSE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ft.com/content/e7ff9e85-7472-40d8-...</td>\n",
       "      <td>Eric Platt</td>\n",
       "      <td>Retail investors help lift Warren Buffett’s Be...</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>17:00:51</td>\n",
       "      <td>Warren Buffett’s Berkshire Hathaway surged to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ft.com/content/51548b4e-4046-495a-...</td>\n",
       "      <td>Moira O’Neill</td>\n",
       "      <td>How to help children pay for university</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>04:00:46</td>\n",
       "      <td>The ever-growing burden of financing universit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url           author  \\\n",
       "0  https://www.ft.com/content/16ac973e-5fb4-40a8-...        Ian Smith   \n",
       "1  https://www.ft.com/content/9f0308fd-027e-4005-...      Laura Onita   \n",
       "2  https://www.ft.com/content/997808ab-8226-45b2-...  Mitchell Labiak   \n",
       "3  https://www.ft.com/content/e7ff9e85-7472-40d8-...       Eric Platt   \n",
       "4  https://www.ft.com/content/51548b4e-4046-495a-...    Moira O’Neill   \n",
       "\n",
       "                                             heading        date      time  \\\n",
       "0  European insurers say US backlash has damaged ...  2023-08-12  13:00:11   \n",
       "1       How high street stalwart Wilko came unstuck   2023-08-11  03:00:46   \n",
       "2  Directors’ Deals: Segro chair increases his stake  2023-08-11  17:00:51   \n",
       "3  Retail investors help lift Warren Buffett’s Be...  2023-08-11  17:00:51   \n",
       "4            How to help children pay for university  2023-08-11  04:00:46   \n",
       "\n",
       "                                        article_text  \n",
       "0  The heads of Europe’s largest insurers have wa...  \n",
       "1  Some shelves have lain empty for months as Wil...  \n",
       "2  Segro’s chair has upped his stake in the FTSE ...  \n",
       "3  Warren Buffett’s Berkshire Hathaway surged to ...  \n",
       "4  The ever-growing burden of financing universit...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9076a19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ft.com/content/02e7e67d-8367-427e-...</td>\n",
       "      <td>Anna Nicolaou</td>\n",
       "      <td>Hollywood calls time on golden era of cheap st...</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>The era of cheap streaming is ending, as Holly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ft.com/content/0241d2c2-8f88-4b9d-...</td>\n",
       "      <td>Lucinda Smyth</td>\n",
       "      <td>Painkiller is a surprisingly watchable drama a...</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>14:00:46</td>\n",
       "      <td>Painkiller opens with a woman looking into the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ft.com/content/094c6b7e-f3f0-4a2b-...</td>\n",
       "      <td>Leonard Barden</td>\n",
       "      <td>Chess: Rishi Sunak to announce £500,000 govern...</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>14:48:29</td>\n",
       "      <td>Rishi Sunak will shortly announce £500,000 gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ft.com/content/24ab315b-b12f-48fa-...</td>\n",
       "      <td>Harriet Agnew</td>\n",
       "      <td>Asset Management: a short history of the bond ...</td>\n",
       "      <td>2023-08-07</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>One bit of programming to start: school’s out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ft.com/content/d83031e2-7d2f-4791-...</td>\n",
       "      <td>Jo Ellison</td>\n",
       "      <td>HTSI editor’s letter: finding summer’s pockets...</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>10:00:11</td>\n",
       "      <td>In our only issue during August, I hope this f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url          author  \\\n",
       "0  https://www.ft.com/content/02e7e67d-8367-427e-...   Anna Nicolaou   \n",
       "1  https://www.ft.com/content/0241d2c2-8f88-4b9d-...   Lucinda Smyth   \n",
       "2  https://www.ft.com/content/094c6b7e-f3f0-4a2b-...  Leonard Barden   \n",
       "3  https://www.ft.com/content/24ab315b-b12f-48fa-...   Harriet Agnew   \n",
       "4  https://www.ft.com/content/d83031e2-7d2f-4791-...      Jo Ellison   \n",
       "\n",
       "                                             heading        date      time  \\\n",
       "0  Hollywood calls time on golden era of cheap st...  2023-08-12  13:00:00   \n",
       "1  Painkiller is a surprisingly watchable drama a...  2023-08-11  14:00:46   \n",
       "2  Chess: Rishi Sunak to announce £500,000 govern...  2023-08-08  14:48:29   \n",
       "3  Asset Management: a short history of the bond ...  2023-08-07  05:00:00   \n",
       "4  HTSI editor’s letter: finding summer’s pockets...  2023-08-05  10:00:11   \n",
       "\n",
       "                                        article_text  \n",
       "0  The era of cheap streaming is ending, as Holly...  \n",
       "1  Painkiller opens with a woman looking into the...  \n",
       "2  Rishi Sunak will shortly announce £500,000 gov...  \n",
       "3  One bit of programming to start: school’s out ...  \n",
       "4  In our only issue during August, I hope this f...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c61af91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Zacks Analyst Blog Highlights Amazon.com, ...</td>\n",
       "      <td>Zacks Equity Research</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>10:50:00</td>\n",
       "      <td>For Immediate Release\\nChicago, IL – August 8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Top Stock Reports for Amazon.com, Netflix &amp; Am...</td>\n",
       "      <td>Mark Vickery</td>\n",
       "      <td>2023-08-07</td>\n",
       "      <td>20:08:00</td>\n",
       "      <td>Monday, August 7, 2023\\nThe Zacks Research Dai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it foolish to buy Netflix shares?</td>\n",
       "      <td>Gordon Best</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>11:00:02</td>\n",
       "      <td>Image source: Getty Images\\nNetflix\\n(NASDAQ:N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netflix reworking Microsoft deal, bringing dow...</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>07:27:34</td>\n",
       "      <td>Investing.com -- Netflix (NASDAQ:NFLX) is rewo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netflix reworks Microsoft pact, lowers ad pric...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>04:10:03</td>\n",
       "      <td>(Reuters) -Netflix is restructuring its advert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline                 author  \\\n",
       "0  The Zacks Analyst Blog Highlights Amazon.com, ...  Zacks Equity Research   \n",
       "1  Top Stock Reports for Amazon.com, Netflix & Am...           Mark Vickery   \n",
       "2               Is it foolish to buy Netflix shares?            Gordon Best   \n",
       "3  Netflix reworking Microsoft deal, bringing dow...          Investing.com   \n",
       "4  Netflix reworks Microsoft pact, lowers ad pric...                Reuters   \n",
       "\n",
       "         date      time                                            content  \n",
       "0  2023-08-08  10:50:00  For Immediate Release\\nChicago, IL – August 8,...  \n",
       "1  2023-08-07  20:08:00  Monday, August 7, 2023\\nThe Zacks Research Dai...  \n",
       "2  2023-08-04  11:00:02  Image source: Getty Images\\nNetflix\\n(NASDAQ:N...  \n",
       "3  2023-07-27  07:27:34  Investing.com -- Netflix (NASDAQ:NFLX) is rewo...  \n",
       "4  2023-07-27  04:10:03  (Reuters) -Netflix is restructuring its advert...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5_yahoo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dda5c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Merged DataFrame: (2624, 6)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the DataFrames into a single DataFrame\n",
    "merged_df = pd.concat([df_1, df_2, df_3, df_4], ignore_index=True)\n",
    "\n",
    "# Print the shape of the merged DataFrame\n",
    "print(\"Shape of Merged DataFrame:\", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26aa58ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>https://www.ft.com/content/02e7e67d-8367-427e-...</td>\n",
       "      <td>Anna Nicolaou</td>\n",
       "      <td>Hollywood calls time on golden era of cheap st...</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>The era of cheap streaming is ending, as Holly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>https://www.ft.com/content/16ac973e-5fb4-40a8-...</td>\n",
       "      <td>Ian Smith</td>\n",
       "      <td>European insurers say US backlash has damaged ...</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>13:00:11</td>\n",
       "      <td>The heads of Europe’s largest insurers have wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>https://www.ft.com/content/63819fbd-18b3-44b9-...</td>\n",
       "      <td>Andrew Edgecliffe-Johnson</td>\n",
       "      <td>Are ‘working capitalists’ the answer to the po...</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>13:00:46</td>\n",
       "      <td>This article is an on-site version of our Swam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>https://www.ft.com/content/51548b4e-4046-495a-...</td>\n",
       "      <td>Moira O’Neill</td>\n",
       "      <td>How to help children pay for university</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>04:00:46</td>\n",
       "      <td>The ever-growing burden of financing universit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>https://www.ft.com/content/fc6fbb6d-47e7-43e0-...</td>\n",
       "      <td>Jude Webber</td>\n",
       "      <td>DUP urges recall of UK parliament over Norther...</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>19:52:37</td>\n",
       "      <td>Northern Ireland’s biggest pro-UK party is see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "1867  https://www.ft.com/content/02e7e67d-8367-427e-...   \n",
       "1061  https://www.ft.com/content/16ac973e-5fb4-40a8-...   \n",
       "1075  https://www.ft.com/content/63819fbd-18b3-44b9-...   \n",
       "1065  https://www.ft.com/content/51548b4e-4046-495a-...   \n",
       "1076  https://www.ft.com/content/fc6fbb6d-47e7-43e0-...   \n",
       "\n",
       "                         author  \\\n",
       "1867              Anna Nicolaou   \n",
       "1061                  Ian Smith   \n",
       "1075  Andrew Edgecliffe-Johnson   \n",
       "1065              Moira O’Neill   \n",
       "1076                Jude Webber   \n",
       "\n",
       "                                                heading        date      time  \\\n",
       "1867  Hollywood calls time on golden era of cheap st...  2023-08-12  13:00:00   \n",
       "1061  European insurers say US backlash has damaged ...  2023-08-12  13:00:11   \n",
       "1075  Are ‘working capitalists’ the answer to the po...  2023-08-11  13:00:46   \n",
       "1065            How to help children pay for university  2023-08-11  04:00:46   \n",
       "1076  DUP urges recall of UK parliament over Norther...  2023-08-11  19:52:37   \n",
       "\n",
       "                                           article_text  \n",
       "1867  The era of cheap streaming is ending, as Holly...  \n",
       "1061  The heads of Europe’s largest insurers have wa...  \n",
       "1075  This article is an on-site version of our Swam...  \n",
       "1065  The ever-growing burden of financing universit...  \n",
       "1076  Northern Ireland’s biggest pro-UK party is see...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by the 'date' column in descending order\n",
    "merged_df = merged_df.sort_values(by='date', ascending=False)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "358b1826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>https://www.ft.com/content/e9d7e4de-b2b6-11e7-...</td>\n",
       "      <td>Tim Bradshaw</td>\n",
       "      <td>Netflix subscriber growth tops estimates</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>00:02:17</td>\n",
       "      <td>Netflix attracted more new subscribers than ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>https://www.ft.com/content/56fb3b11-a23a-3f60-...</td>\n",
       "      <td>Tim Bradshaw</td>\n",
       "      <td>Netflix subscriber growth tops estimates, reve...</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>20:46:47</td>\n",
       "      <td>Netflix posted a 30 per cent jump in revenue t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>https://www.ft.com/content/48c368c1-606b-3859-...</td>\n",
       "      <td>Tim Bradshaw</td>\n",
       "      <td>Netflix rules out bid for Weinstein Company</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>22:52:33</td>\n",
       "      <td>Netflix has effectively ruled itself out of bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>https://www.ft.com/content/e6679a36-bfc2-3ac0-...</td>\n",
       "      <td>Pan Kwan Yuk</td>\n",
       "      <td>Netflix climbs past $200 for first time after ...</td>\n",
       "      <td>2017-10-13</td>\n",
       "      <td>15:07:57</td>\n",
       "      <td>Shares in Netflix briefly crossed the $200 mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>https://www.ft.com/content/10ec51db-104d-37c6-...</td>\n",
       "      <td>Jessica Dye</td>\n",
       "      <td>Netflix shares zip higher on subscription pric...</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>15:36:57</td>\n",
       "      <td>Investors are tuning into Netflix after the vi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url        author  \\\n",
       "1056  https://www.ft.com/content/e9d7e4de-b2b6-11e7-...  Tim Bradshaw   \n",
       "1057  https://www.ft.com/content/56fb3b11-a23a-3f60-...  Tim Bradshaw   \n",
       "1058  https://www.ft.com/content/48c368c1-606b-3859-...  Tim Bradshaw   \n",
       "1059  https://www.ft.com/content/e6679a36-bfc2-3ac0-...  Pan Kwan Yuk   \n",
       "1060  https://www.ft.com/content/10ec51db-104d-37c6-...   Jessica Dye   \n",
       "\n",
       "                                                heading        date      time  \\\n",
       "1056           Netflix subscriber growth tops estimates  2017-10-17  00:02:17   \n",
       "1057  Netflix subscriber growth tops estimates, reve...  2017-10-16  20:46:47   \n",
       "1058        Netflix rules out bid for Weinstein Company  2017-10-16  22:52:33   \n",
       "1059  Netflix climbs past $200 for first time after ...  2017-10-13  15:07:57   \n",
       "1060  Netflix shares zip higher on subscription pric...  2017-10-05  15:36:57   \n",
       "\n",
       "                                           article_text  \n",
       "1056  Netflix attracted more new subscribers than ex...  \n",
       "1057  Netflix posted a 30 per cent jump in revenue t...  \n",
       "1058  Netflix has effectively ruled itself out of bi...  \n",
       "1059  Shares in Netflix briefly crossed the $200 mar...  \n",
       "1060  Investors are tuning into Netflix after the vi...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b51f026d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "957f9a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate rows based on the 'url' column\n",
    "duplicate_rows = merged_df[merged_df.duplicated(subset=['url'])]\n",
    "\n",
    "# Display the duplicate rows\n",
    "len(duplicate_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3108afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on the 'url' column\n",
    "merged_df = merged_df.drop_duplicates(subset=['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb22d5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>https://www.ft.com/content/02e7e67d-8367-427e-...</td>\n",
       "      <td>Anna Nicolaou</td>\n",
       "      <td>Hollywood calls time on golden era of cheap st...</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>The era of cheap streaming is ending, as Holly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>https://www.ft.com/content/16ac973e-5fb4-40a8-...</td>\n",
       "      <td>Ian Smith</td>\n",
       "      <td>European insurers say US backlash has damaged ...</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>13:00:11</td>\n",
       "      <td>The heads of Europe’s largest insurers have wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>https://www.ft.com/content/63819fbd-18b3-44b9-...</td>\n",
       "      <td>Andrew Edgecliffe-Johnson</td>\n",
       "      <td>Are ‘working capitalists’ the answer to the po...</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>13:00:46</td>\n",
       "      <td>This article is an on-site version of our Swam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>https://www.ft.com/content/51548b4e-4046-495a-...</td>\n",
       "      <td>Moira O’Neill</td>\n",
       "      <td>How to help children pay for university</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>04:00:46</td>\n",
       "      <td>The ever-growing burden of financing universit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>https://www.ft.com/content/fc6fbb6d-47e7-43e0-...</td>\n",
       "      <td>Jude Webber</td>\n",
       "      <td>DUP urges recall of UK parliament over Norther...</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>19:52:37</td>\n",
       "      <td>Northern Ireland’s biggest pro-UK party is see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "1867  https://www.ft.com/content/02e7e67d-8367-427e-...   \n",
       "1061  https://www.ft.com/content/16ac973e-5fb4-40a8-...   \n",
       "1075  https://www.ft.com/content/63819fbd-18b3-44b9-...   \n",
       "1065  https://www.ft.com/content/51548b4e-4046-495a-...   \n",
       "1076  https://www.ft.com/content/fc6fbb6d-47e7-43e0-...   \n",
       "\n",
       "                         author  \\\n",
       "1867              Anna Nicolaou   \n",
       "1061                  Ian Smith   \n",
       "1075  Andrew Edgecliffe-Johnson   \n",
       "1065              Moira O’Neill   \n",
       "1076                Jude Webber   \n",
       "\n",
       "                                                heading        date      time  \\\n",
       "1867  Hollywood calls time on golden era of cheap st...  2023-08-12  13:00:00   \n",
       "1061  European insurers say US backlash has damaged ...  2023-08-12  13:00:11   \n",
       "1075  Are ‘working capitalists’ the answer to the po...  2023-08-11  13:00:46   \n",
       "1065            How to help children pay for university  2023-08-11  04:00:46   \n",
       "1076  DUP urges recall of UK parliament over Norther...  2023-08-11  19:52:37   \n",
       "\n",
       "                                           article_text  \n",
       "1867  The era of cheap streaming is ending, as Holly...  \n",
       "1061  The heads of Europe’s largest insurers have wa...  \n",
       "1075  This article is an on-site version of our Swam...  \n",
       "1065  The ever-growing burden of financing universit...  \n",
       "1076  Northern Ireland’s biggest pro-UK party is see...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4576e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>https://www.ft.com/content/e9d7e4de-b2b6-11e7-...</td>\n",
       "      <td>Tim Bradshaw</td>\n",
       "      <td>Netflix subscriber growth tops estimates</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>00:02:17</td>\n",
       "      <td>Netflix attracted more new subscribers than ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>https://www.ft.com/content/56fb3b11-a23a-3f60-...</td>\n",
       "      <td>Tim Bradshaw</td>\n",
       "      <td>Netflix subscriber growth tops estimates, reve...</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>20:46:47</td>\n",
       "      <td>Netflix posted a 30 per cent jump in revenue t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>https://www.ft.com/content/48c368c1-606b-3859-...</td>\n",
       "      <td>Tim Bradshaw</td>\n",
       "      <td>Netflix rules out bid for Weinstein Company</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>22:52:33</td>\n",
       "      <td>Netflix has effectively ruled itself out of bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>https://www.ft.com/content/e6679a36-bfc2-3ac0-...</td>\n",
       "      <td>Pan Kwan Yuk</td>\n",
       "      <td>Netflix climbs past $200 for first time after ...</td>\n",
       "      <td>2017-10-13</td>\n",
       "      <td>15:07:57</td>\n",
       "      <td>Shares in Netflix briefly crossed the $200 mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>https://www.ft.com/content/10ec51db-104d-37c6-...</td>\n",
       "      <td>Jessica Dye</td>\n",
       "      <td>Netflix shares zip higher on subscription pric...</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>15:36:57</td>\n",
       "      <td>Investors are tuning into Netflix after the vi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url        author  \\\n",
       "1056  https://www.ft.com/content/e9d7e4de-b2b6-11e7-...  Tim Bradshaw   \n",
       "1057  https://www.ft.com/content/56fb3b11-a23a-3f60-...  Tim Bradshaw   \n",
       "1058  https://www.ft.com/content/48c368c1-606b-3859-...  Tim Bradshaw   \n",
       "1059  https://www.ft.com/content/e6679a36-bfc2-3ac0-...  Pan Kwan Yuk   \n",
       "1060  https://www.ft.com/content/10ec51db-104d-37c6-...   Jessica Dye   \n",
       "\n",
       "                                                heading        date      time  \\\n",
       "1056           Netflix subscriber growth tops estimates  2017-10-17  00:02:17   \n",
       "1057  Netflix subscriber growth tops estimates, reve...  2017-10-16  20:46:47   \n",
       "1058        Netflix rules out bid for Weinstein Company  2017-10-16  22:52:33   \n",
       "1059  Netflix climbs past $200 for first time after ...  2017-10-13  15:07:57   \n",
       "1060  Netflix shares zip higher on subscription pric...  2017-10-05  15:36:57   \n",
       "\n",
       "                                           article_text  \n",
       "1056  Netflix attracted more new subscribers than ex...  \n",
       "1057  Netflix posted a 30 per cent jump in revenue t...  \n",
       "1058  Netflix has effectively ruled itself out of bi...  \n",
       "1059  Shares in Netflix briefly crossed the $200 mar...  \n",
       "1060  Investors are tuning into Netflix after the vi...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9714691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2046, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "107a52bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df.to_csv('FT_2017_10_05_2023_08_12_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f84a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "businessanalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
