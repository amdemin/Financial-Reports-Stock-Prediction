{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load local modules\n",
    "from module_text_blocks import split_text_into_blocks, clean_text_blocks\n",
    "\n",
    "# Import credentials\n",
    "from credentials_amazon import *\n",
    "\n",
    "# Connect to Amazon API\n",
    "import boto3\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
    "os.environ[\"AWS_REGION\"] = AWS_REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon_analyze_sentiment(text):\n",
    "    comprehend = boto3.client(service_name='comprehend', region_name=\"us-west-2\")\n",
    "    sentiment_response = comprehend.detect_sentiment(Text=text, LanguageCode='en')\n",
    "    return sentiment_response[\"SentimentScore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_by_chars(text, num_chars):\n",
    "    \"\"\"Split the input text every num_chars characters.\"\"\"\n",
    "    return [text[i:i+num_chars] for i in range(0, len(text), num_chars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pdf text and headings from the pickle file\n",
    "pdf_texts = pickle.load(open(\"pdf_texts.pkl\", \"rb\"))\n",
    "pdf_headings = pickle.load(open(\"pdf_headings.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea1bfa6551248438b0371a11aec6065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693\n",
      "788\n",
      "2658\n",
      "2892\n",
      "1502\n",
      "607\n",
      "3456\n"
     ]
    }
   ],
   "source": [
    "polarity_scores = {}\n",
    "pdf_lists = [\"FINAL-Q1-19-Shareholder-Letter\"]\n",
    "pdf_lists = [\"FINAL-Q2-20-Shareholder-Letter-V3-with-Tables\"]\n",
    "\n",
    "for pdf_name in tqdm(pdf_lists):\n",
    "\n",
    "    try:\n",
    "\n",
    "        text_blocks_scores = []\n",
    "\n",
    "        text = pdf_texts[pdf_name]\n",
    "        headings = pdf_headings[pdf_name]\n",
    "\n",
    "        # split the text into blocks based on the headings\n",
    "        text_blocks = split_text_into_blocks(text, headings)\n",
    "        # clean the text blocks\n",
    "        text_blocks = clean_text_blocks(text_blocks)\n",
    "\n",
    "        # iterate over the text blocks individually, otherwise single request with all text will fail\n",
    "        if len(headings) > 0:\n",
    "            for heading, text in text_blocks.items():\n",
    "\n",
    "                if heading == \"Reference\":\n",
    "                    break\n",
    "\n",
    "                # print(len(text))\n",
    "\n",
    "                if len(text) == 0:\n",
    "                    continue\n",
    "\n",
    "                # the prompt for amazon sentiment analysis should be less than 5000 bytes\n",
    "                if len(text) < 4750:\n",
    "                    polarity_score = amazon_analyze_sentiment(text)\n",
    "                    key = max(polarity_score, key=polarity_score.get)\n",
    "                    text_blocks_scores.append(polarity_score[key])\n",
    "                \n",
    "                # split into multi blocks if the text is too long\n",
    "                else:\n",
    "                    text_blocks = split_text_by_chars(text, 4500)\n",
    "                    for text in text_blocks:\n",
    "                        polarity_score = amazon_analyze_sentiment(text)\n",
    "                        key = max(polarity_score, key=polarity_score.get)\n",
    "                        text_blocks_scores.append(polarity_score[key])\n",
    "\n",
    "        else:\n",
    "            text_blocks = split_text_by_chars(text, 4500)\n",
    "            for text in text_blocks:\n",
    "                polarity_score = amazon_analyze_sentiment(text)\n",
    "                key = max(polarity_score, key=polarity_score.get)\n",
    "                text_blocks_scores.append(polarity_score[key])\n",
    "                \n",
    "        \n",
    "        polarity_scores[pdf_name] = np.mean(text_blocks_scores)\n",
    "        # print(text_blocks_scores)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(f\"Exception occurred in file {pdf_name}\")\n",
    "        print(f\"Exception message: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_polarity = pd.DataFrame(list(polarity_scores.items()), columns=['pdf_name', 'polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINAL-Q2-20-Shareholder-Letter-V3-with-Tables</td>\n",
       "      <td>0.846756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pdf_name  polarity\n",
       "0  FINAL-Q2-20-Shareholder-Letter-V3-with-Tables  0.846756"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_polarity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "# amazon_polarity.to_csv(\"Scores/amazon_polarity.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
