{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all necessary libraries and local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Load local preprocesing modules\n",
    "sys.path.append(\"Pipeline/\")\n",
    "from module_text_blocks import split_text_into_blocks, clean_text_blocks\n",
    "from module_process_pdf import process_pdf\n",
    "from module_scrape_pdf import scrape_pdf\n",
    "from module_functions import normalise_score\n",
    "\n",
    "# Load local model modules\n",
    "sys.path.append(\"Models/\")\n",
    "from module_sentiment_textblob import calculate_textblob_polarity\n",
    "from module_sentiment_google import calculate_google_polarity\n",
    "from module_sentiment_amazon import calculate_amazon_polarity\n",
    "from module_sentiment_openai import calculate_openai_polarity\n",
    "from module_sentiment_bert import calculate_bert_polarity\n",
    "from module_sentiment_roberta import calculate_roberta_polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Full Pipeline (TextBlob Model Only) - Approximately 15-20 Seconds Running Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL-Q2-23-Shareholder-Letter TextBlob sentiment score: 0.6603495902734645\n",
      "Time taken for TextBlob model to calculate sentiment:  0.03366374969482422\n",
      " \n",
      " \n",
      "Total time taken for full pipeline to run:  18.89583158493042\n"
     ]
    }
   ],
   "source": [
    "main_start_time = time.time()\n",
    "\n",
    "# Load historic models min and max values for normalisation\n",
    "historic_df = pd.read_csv(\"Src/historic_min_max.csv\")\n",
    "\n",
    "# Models with corresponding local functions to calculate sentiment score\n",
    "models = {\n",
    "    \"TextBlob\": calculate_textblob_polarity,\n",
    "    \"Amazon\": calculate_amazon_polarity,\n",
    "    \"Google\": calculate_google_polarity,\n",
    "    \"OpenAI\": calculate_openai_polarity,\n",
    "    \"BERT\": calculate_bert_polarity,\n",
    "    \"RoBERTa\": calculate_roberta_polarity,\n",
    "}\n",
    "\n",
    "# Models with True or False boolean to indicate whether to run the model or not\n",
    "models_bool = {\n",
    "    \"TextBlob\": True,\n",
    "    \"Amazon\": False,\n",
    "    \"Google\": False,\n",
    "    \"OpenAI\": False,\n",
    "    \"BERT\": False,\n",
    "    \"RoBERTa\": False,\n",
    "}\n",
    "\n",
    "# scrape PDF from Netflix website\n",
    "Netflix_scraping_page = \"https://ir.netflix.net/financials/quarterly-earnings/default.aspx\"\n",
    "# change to scrape_all=False to only scrape the latest pdf, otherwise all pdfs will be scraped\n",
    "download_folder = \"Pipeline\" # specify folder to download pdfs to, default is Pipeline\n",
    "scrape_pdf(Netflix_scraping_page, scrape_all=False, download_folder=download_folder)\n",
    "\n",
    "# get all downloaded files from the dedicated folder\n",
    "pipeline_files = [download_folder + '/' + file for file in os.listdir(download_folder) if file.endswith('.pdf')]\n",
    "\n",
    "# Transform pdf files into texts and headings and store them as dictionaries\n",
    "pdf_texts, pdf_headings, pdf_headings_context = process_pdf(pipeline_files)\n",
    "\n",
    "# Iterate over pdf texts\n",
    "for pdf_file in pdf_texts:\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Get text, headings and headings context\n",
    "        text = pdf_texts[pdf_file]\n",
    "        headings = pdf_headings[pdf_file]\n",
    "        headings_context = pdf_headings_context[pdf_file]\n",
    "\n",
    "        # Split text into blocks\n",
    "        text_blocks = split_text_into_blocks(text, headings, headings_context)\n",
    "\n",
    "        # Clean text blocks\n",
    "        text_blocks = clean_text_blocks(text_blocks)\n",
    "\n",
    "        # Iterate over models\n",
    "        for model_name, model_function in models.items():\n",
    "            \n",
    "            # skip model if bool is False\n",
    "            if models_bool[model_name] == False:\n",
    "                continue\n",
    "            \n",
    "            # set start time\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Calculate sentiment score\n",
    "            sentiment_score = model_function(text_blocks, headings, text)\n",
    "            \n",
    "            # Normalise sentiment score (except for OpenAI) \n",
    "            if model_name != \"OpenAI\": \n",
    "                sentiment_score = normalise_score(sentiment_score, historic_df[historic_df[\"Name\"] == model_name][\"Min\"].values[0], historic_df[historic_df[\"Name\"] == model_name][\"Max\"].values[0], historic_df.iloc[0, 1], historic_df.iloc[0, 2])\n",
    "        \n",
    "            # set end time\n",
    "            end_time = time.time()\n",
    "            # print sentiment score\n",
    "            print(f\"{pdf_file} {model_name} sentiment score: {sentiment_score}\")\n",
    "            # print processing time\n",
    "            print(f\"Time taken for {model_name} model to calculate sentiment: \", end_time - start_time)#\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(f\"Error: {e}\")\n",
    "        continue\n",
    "\n",
    "main_end_time = time.time()\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(f\"Total time taken for full pipeline to run: \", main_end_time - main_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Full Pipeline (Google and OpenAI Models Only) - Approximately 25-35 Seconds Running Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL-Q2-23-Shareholder-Letter Google sentiment score: 0.39000000804662704\n",
      "Time taken for Google model to calculate sentiment:  4.226781129837036\n",
      "FINAL-Q2-23-Shareholder-Letter OpenAI sentiment score: 0.25\n",
      "Time taken for OpenAI model to calculate sentiment:  11.225489854812622\n",
      " \n",
      " \n",
      "Total time taken for full pipeline to run:  32.99209499359131\n"
     ]
    }
   ],
   "source": [
    "main_start_time = time.time()\n",
    "\n",
    "# Load historic models min and max values for normalisation\n",
    "historic_df = pd.read_csv(\"Src/historic_min_max.csv\")\n",
    "\n",
    "# Models with corresponding local functions to calculate sentiment score\n",
    "models = {\n",
    "    \"TextBlob\": calculate_textblob_polarity,\n",
    "    \"Amazon\": calculate_amazon_polarity,\n",
    "    \"Google\": calculate_google_polarity,\n",
    "    \"OpenAI\": calculate_openai_polarity,\n",
    "    \"BERT\": calculate_bert_polarity,\n",
    "    \"RoBERTa\": calculate_roberta_polarity,\n",
    "}\n",
    "\n",
    "# Models with True or False boolean to indicate whether to run the model or not\n",
    "models_bool = {\n",
    "    \"TextBlob\": False,\n",
    "    \"Amazon\": False,\n",
    "    \"Google\": True,\n",
    "    \"OpenAI\": True,\n",
    "    \"BERT\": False,\n",
    "    \"RoBERTa\": False,\n",
    "}\n",
    "\n",
    "\n",
    "# scrape PDF from Netflix website\n",
    "Netflix_scraping_page = \"https://ir.netflix.net/financials/quarterly-earnings/default.aspx\"\n",
    "# change to scrape_all=False to only scrape the latest pdf, otherwise all pdfs will be scraped\n",
    "download_folder = \"Pipeline\" # specify folder to download pdfs to, default is Pipeline\n",
    "scrape_pdf(Netflix_scraping_page, scrape_all=False, download_folder=download_folder)\n",
    "\n",
    "# get all downloaded files from the dedicated folder\n",
    "pipeline_files = [download_folder + '/' + file for file in os.listdir(download_folder) if file.endswith('.pdf')]\n",
    "\n",
    "# Transform pdf files into texts and headings and store them as dictionaries\n",
    "pdf_texts, pdf_headings, pdf_headings_context = process_pdf(pipeline_files)\n",
    "\n",
    "# Iterate over pdf texts\n",
    "for pdf_file in pdf_texts:\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Get text, headings and headings context\n",
    "        text = pdf_texts[pdf_file]\n",
    "        headings = pdf_headings[pdf_file]\n",
    "        headings_context = pdf_headings_context[pdf_file]\n",
    "\n",
    "        # Split text into blocks\n",
    "        text_blocks = split_text_into_blocks(text, headings, headings_context)\n",
    "\n",
    "        # Clean text blocks\n",
    "        text_blocks = clean_text_blocks(text_blocks)\n",
    "\n",
    "        # Iterate over models\n",
    "        for model_name, model_function in models.items():\n",
    "            \n",
    "            # skip model if bool is False\n",
    "            if models_bool[model_name] == False:\n",
    "                continue\n",
    "            \n",
    "            # set start time\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Calculate sentiment score\n",
    "            sentiment_score = model_function(text_blocks, headings, text)\n",
    "            \n",
    "            # Normalise sentiment score (except for OpenAI) \n",
    "            if model_name != \"OpenAI\": \n",
    "                sentiment_score = normalise_score(sentiment_score, historic_df[historic_df[\"Name\"] == model_name][\"Min\"].values[0], historic_df[historic_df[\"Name\"] == model_name][\"Max\"].values[0], historic_df.iloc[0, 1], historic_df.iloc[0, 2])\n",
    "        \n",
    "            # set end time\n",
    "            end_time = time.time()\n",
    "            # print sentiment score\n",
    "            print(f\"{pdf_file} {model_name} sentiment score: {sentiment_score}\")\n",
    "            # print processing time\n",
    "            print(f\"Time taken for {model_name} model to calculate sentiment: \", end_time - start_time)#\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(f\"Error: {e}\")\n",
    "        continue\n",
    "\n",
    "main_end_time = time.time()\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(f\"Total time taken for full pipeline to run: \", main_end_time - main_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-Full Pipeline (No Scraping & PDF Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latest shareholder text and headings from the pickle file\n",
    "pdf_texts = pickle.load(open(\"Src/pdf_texts_last_report.pickle\", \"rb\"))                        # Texts are extracted from the pdf\n",
    "pdf_headings = pickle.load(open(\"Src/pdf_headings_last_report.pickle\", \"rb\"))                  # Headings are extracted from the pdf text\n",
    "pdf_headings_context = pickle.load(open(\"Src/pdf_headings_context_last_report.pickle\", \"rb\"))  # Surrounding text of headings helps to identify headings correctly and avoid duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historic models min and max values for normalisation\n",
    "historic_df = pd.read_csv(\"Src/historic_min_max.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL-Q2-23-Shareholder-Letter TextBlob sentiment score: 0.6603495902734645\n",
      "Time taken for TextBlob to process text:  0.03193259239196777\n",
      "Error: name 'sentiment_scores' is not defined\n",
      " \n",
      " \n",
      "Time taken for semi-full pipeline to run:  0.033925771713256836\n"
     ]
    }
   ],
   "source": [
    "# Models with corresponding local functions to calculate sentiment score\n",
    "models = {\n",
    "    \"TextBlob\": calculate_textblob_polarity,\n",
    "    \"Amazon\": calculate_amazon_polarity,\n",
    "    \"Google\": calculate_google_polarity,\n",
    "    \"OpenAI\": calculate_openai_polarity,\n",
    "    \"BERT\": calculate_bert_polarity,\n",
    "    \"RoBERTa\": calculate_roberta_polarity,\n",
    "}\n",
    "\n",
    "# Models with True or False boolean to indicate whether to run the model or not\n",
    "models_bool = {\n",
    "    \"TextBlob\": True,\n",
    "    \"Amazon\": False,\n",
    "    \"Google\": False,\n",
    "    \"OpenAI\": False,\n",
    "    \"BERT\": False,\n",
    "    \"RoBERTa\": False,\n",
    "}\n",
    "\n",
    "main_start_time = time.time()\n",
    "\n",
    "# Iterate over pdf files\n",
    "for pdf_file in pdf_texts:\n",
    "\n",
    "    try:\n",
    "\n",
    "        text = pdf_texts[pdf_file]\n",
    "        headings = pdf_headings[pdf_file]\n",
    "        headings_context = pdf_headings_context[pdf_file]\n",
    "\n",
    "        # Split text into blocks\n",
    "        text_blocks = split_text_into_blocks(text, headings, headings_context)\n",
    "\n",
    "        # Clean text blocks\n",
    "        text_blocks = clean_text_blocks(text_blocks)\n",
    "\n",
    "        # Iterate over models\n",
    "        for model_name, model_function in models.items():\n",
    "\n",
    "            # skip model if bool is False\n",
    "            if models_bool[model_name] == False:\n",
    "                continue\n",
    "            \n",
    "            # set start time\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Calculate sentiment score\n",
    "            sentiment_score = model_function(text_blocks, headings, text)\n",
    "            \n",
    "            # Normalise sentiment score (except for OpenAI) \n",
    "            if model_name != \"OpenAI\": \n",
    "                sentiment_score = normalise_score(sentiment_score, historic_df[historic_df[\"Name\"] == model_name][\"Min\"].values[0], historic_df[historic_df[\"Name\"] == model_name][\"Max\"].values[0], historic_df.iloc[0, 1], historic_df.iloc[0, 2])\n",
    "\n",
    "            # set end time\n",
    "            end_time = time.time()\n",
    "            # print sentiment score\n",
    "            print(f\"{pdf_file} {model_name} sentiment score: {sentiment_score}\")\n",
    "            # print processing time\n",
    "            print(f\"Time taken for {model_name} to process text: \", end_time - start_time)\n",
    "        \n",
    "        # Calculate the average sentiment score\n",
    "        average_sentiment_score = np.average(sentiment_scores, weights=[1.0, 1.0])\n",
    "\n",
    "        # Print the average sentiment score\n",
    "        print(f\"{pdf_file} weighted average sentiment score: {average_sentiment_score}\")\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "main_end_time = time.time()\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(f\"Time taken for semi-full pipeline to run: \", main_end_time - main_start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARP_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
